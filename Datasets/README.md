This Readme file includes description of datasets of the folder. 

The following table includes details of Labelled and Unlabelled datasets which are used in this study. 

Table 1. Dataset Specs. 
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-7btt{border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-c3ow"></th>
    <th class="tg-7btt">   <br>Dataset   </th>
    <th class="tg-7btt">   <br>Length of Corpus   </th>
    <th class="tg-7btt">   <br>count of tokens: <br>original corpus   </th>
    <th class="tg-7btt">   <br>count of tokens: <br>cleaned corpus   </th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-uzvj" rowspan="3">Labelled <br>Dataset</td>
    <td class="tg-c3ow">   <br>Amazon Reviews   </td>
    <td class="tg-c3ow">   <br>973   </td>
    <td class="tg-c3ow">10,246</td>
    <td class="tg-c3ow">3,688 </td>
  </tr>
  <tr>
    <td class="tg-c3ow">   <br>Yelp Reviews   </td>
    <td class="tg-c3ow">   <br>976   </td>
    <td class="tg-c3ow">10,894</td>
    <td class="tg-c3ow">3,859</td>
  </tr>
  <tr>
    <td class="tg-c3ow">Computer Science <br>Abstracts</td>
    <td class="tg-c3ow">   <br>100   </td>
    <td class="tg-c3ow">19,217</td>
    <td class="tg-c3ow">9,960</td>
  </tr>
  <tr>
    <td class="tg-uzvj" rowspan="2">Unlabelled <br>Dataset</td>
    <td class="tg-c3ow">   <br>Computing Forever I   </td>
    <td class="tg-c3ow">   <br>994   </td>
    <td class="tg-c3ow">31,743</td>
    <td class="tg-c3ow">   <br>14,995    </td>
  </tr>
  <tr>
    <td class="tg-c3ow">   <br>Computing Forever II   </td>
    <td class="tg-c3ow">   <br>11,273   </td>
    <td class="tg-c3ow">481,884</td>
    <td class="tg-c3ow">   <br>229,556    </td>
  </tr>
</tbody>
</table>

### ------------------------------------------------------------------------------------------
# Labelled Dataset
## Amazon Cell Reviews 
Amazon Celle Reviews is a publicly open dataset. This dataset was originally collected for the problem of product rating prediction. The dataset collected from the cell phone and accessories category in Amazon official website (Amazon.com). Data is labelled with two specific label ratings of 0 and 1 respectively for the negative and positive reviews was employed in this study. The employed corpus in this study, includes 973 documents. The count of tokens from the priginal and preprocessed dataset can be found in Table 1. 


## Yelp Reviews 
Yelp dataset is collected from the reviews published in official Yelp website.  The dataset is labelled with 0 and 1 respectively for the negative and positive reviews. The employed corpus includes 976 documnets.  The count of tokens from the priginal and preprocessed dataset can be found in Table 1. 


## Computer Science Abstract
This corpus is collected by targeting papers published in 4-main principles of computer science research. These domains/Topics are listed herein for future reference:
- Cyber Security
- Software Engineering
- Data Mining 
- Human Computer Interaction

Overall, there are 100 documents in this corpus. 


### ------------------------------------------------------------------------------------------
# Unlabelled Dataset
## Computing Forever I & II
Computing Forever is a successful Irish Alt-tech channel, which has over 10,000 and 113,700 subscribers follow the channel on Telegram and BitChute vlog, respectively. 
For this study the data was collected at two time points (year 2021 and 2023). These dataset are respectively indexed with Computing Forever (I) and (II) annotations and details of which can be table 1. 
