Topic,Title,Abstract,KeyWords
Cyber Security,Cyber Security in the Age of COVID-19: A Timeline and Analysis of Cyber-Crime and Cyber-Attacks during the Pandemic,"Abstract—The COVID-19 pandemic was a remarkable unprecedented event which altered the lives of billions of citizens globally resulting in what became commonly re- ferred to as the new-normal in terms of societal norms and the way we live and work. Aside from the extraordinary impact on society and business as a whole, the pandemic generated a set of unique cyber-crime related circumstances which also affected society and business. The increased anxiety caused by the pandemic heightened the likelihood of cyber-attacks succeeding corresponding with an increase in the number and range of cyber-attacks. This paper analyses the COVID-19 pandemic from a cyber-crime perspective and highlights the range of cyber- attacks experienced globally during the pandemic. Cyber- attacks are analysed and considered within the context of key global events to reveal the modus-operandi of cyber- attack campaigns. The analysis shows how following what appeared to be large gaps between the initial outbreak of the pandemic in China and the first COVID-19 related cyber-attack, attacks steadily became much more prevalent to the point that on some days, 3 or 4 unique cyber-attacks were being reported. The analysis proceeds to utilise the UK as a case study to demonstrate how cyber-criminals leveraged key events and governmental announcements to carefully craft and design cyber-crime campaigns.",Coronavirus COVID-19 cyber security cyber-attack cyber-crime attack timeline home working
Cyber Security,Effectiveness of artificial intelligence techniques against cyber security risks apply of IT industry,"The aim of the researcher was to determine the effectiveness of artificial intelligence techniques against cyber security risks particularly in case of Iraq, Researcher has opted for quantitative method of research design along with primary data. The researcher collected the data from employees working in this IT industry. The sample size for this study was 468 and confirmatory factor analysis, discriminant validity, basic analysis of model and lastly, hypothesis assessment was carried out. The P-values of all variables were obtained as significant apart from expert system which had no significant relation with artificial intelligence and cyber security. Geographical area, sample size, less variables and accessibility was the main issue.",Artificial intelligenceExpert systemNeural agentsCyber-securityIntelligence agents
Cyber Security,A Systematic Review of the State of Cyber-Security in Water Systems,"Critical infrastructure systems are evolving from isolated bespoke systems to those that use general-purpose computing hosts, IoT sensors, edge computing, wireless networks and artificial intelligence. Although this move improves sensing and control capacity and gives better integration with business requirements, it also increases the scope for attack from malicious entities that intend to conduct industrial espionage and sabotage against these systems. In this paper, we review the state of the cyber-security research that is focused on improving the security of the water supply and wastewater collection and treatment systems that form part of the critical national infrastructure. We cover the publication statistics of the research in this area, the aspects of security being addressed, and future work required to achieve better cyber-security for water systems.",smart water systems; cyber–physical security; cyber-security; cyber–physical attacks
Cyber Security,Cyber Security in Control of Grid-Tied Power Electronic Converters—Challenges and Vulnerabilities,"— Grid-tied power electronic converters are key enabling technologies for interfacing renewable energy sources, energy storage, electrical vehicles, microgrids, and high-voltage dc transmission lines with the electrical power grid. As the number of power converters in modern grids continually increases, their monitoring and coordinated control in a way to support the grid have become topics of increased practical and research interest. In connection with this, latest standards have also defined a mandatory set of control parameters for grid-tied converters, which should be adjustable by a remote entity that sends commands through a communication network. While such a remote control capability allows many new control functions in grid-tied converters, it also renders them vulnerable to cyber-attacks. The aim of this article is first to shed light on the portions of the power converter control systems that are vulnerable to cyber-attacks. Next, typical cyber-attacks are overviewed by considering different applications of the gridtied converters. Further, the impact of different types of cyberattacks on grid support functions is studied. Finally, this article is concluded with summary and recommendation for further research.","— Cyber-attacks, cyber-physical systems, distributed generation, voltage source converters"
Cyber Security,A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection," This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.","Cyber analytics, data mining, machine learning."
Cyber Security,Physical Safety and Cyber Security Analysis of Multi-Agent Systems: A Survey of Recent Advances,"Multi-agent systems (MASs) are typically composed of multiple smart entities with independent sensing, communication, computing, and decision-making capabilities. Nowadays, MASs have a wide range of applications in smart grids, smart manufacturing, sensor networks, and intelligent transportation systems. Control of the MASs are often coordinated through information interaction among agents, which is one of the most important factors affecting coordination and cooperation performance. However, unexpected physical faults and cyber attacks on a single agent may spread to other agents via information interaction very quickly, and thus could lead to severe degradation of the whole system performance and even destruction of MASs. This paper is concerned with the safety/security analysis and synthesis of MASs arising from physical faults and cyber attacks, and our goal is to present a comprehensive survey on recent results on fault estimation, detection, diagnosis and fault-tolerant control of MASs, and cyber attack detection and secure control of MASs subject to two typical cyber attacks. Finally, the paper concludes with some potential future research topics on the security issues of MASs.","Consensus, deception attack, deny-of-service (DoS) attack, fault detection, fault estimation, fault tolerant control, multiagent systems."
Cyber Security,Integration of social and IoT technologies: architectural framework for digital transformation and cyber security challenges,"Growing synergies between the Internet of Things (IoT) and Social technologies are contributing to the advances in Cyber Physical Social Systems. Integration of new technologies is facing key challenges related to information security and privacy. This paper explores the interplay and synergetic relationships among these technologies, identifying relevant interactions, key challenges primarily focusing on cybersecurity and privacy. Specific contributions include (1) concise description of digital transformation based on the literature and resulting potential business impact (2) identification of opportunities related to the integration of social and IoT technologies and (3) challenges in technology convergence with a focus on cybersecurity challenges.",Social Internet of Things (SIoT)cyber security and privacy challengesdigital transformationArtificial Intelligence (AI)Cyber Physical Social Systems (CPSS)
Cyber Security,Adversarial Machine Learning Attacks and Defense Methods in the Cyber Security Domain,"In recent years, machine learning algorithms, and more specifically deep learning algorithms, have been widely used in many fields, including cyber security. However, machine learning systems are vulnerable to adversarial attacks, and this limits the application of machine learning, especially in non-stationary, adversarial environments, such as the cyber security domain, where actual adversaries (e.g., malware developers) exist. This article comprehensively summarizes the latest research on adversarial attacks against security solutions based on machine learning techniques and illuminates the risks they pose. First, the adversarial attack methods are characterized based on their stage of occurrence, and the attacker’ s goals and capabilities. Then, we categorize the applications of adversarial attack and defense methods in the cyber security domain. Finally, we highlight some characteristics identified in recent research and discuss the impact of recent advancements in other adversarial learning domains on future research directions in the cyber security domain. To the best of our knowledge, this work is the first to discuss the unique challenges of implementing end-to-end adversarial attacks in the cyber security domain, map them in a unified taxonomy, and use the taxonomy to highlight future research directions.","Adversarial learning, adversarial machine learning, evasion attacks, poisoning attacks, deep learning, adversarial examples, cyber security"
Cyber Security,Big Data Analytics in Cyber Security: Network Traffic and Attacks,"Network attacks, intrusion detection, and intrusion prevention are important topics in cyber security. Network flows and system events generate big data, which often leads to challenges in intrusion detection with high efficiency and good accuracy. This paper focuses on the ‘Volume’, ‘Veracity’, and ‘Variety’ of big data characteristics in network traffic and attacks. Datasets with various data types including numerical data and categorical data (such as status or flag data) are analyzed with the help of R language and its functions. Data duplicates detection and removal, missing values detection, and data quality analysis are also performed. The analysis of masquerades for various users is conducted. In addition, the correlation analysis of variables and a clustering analysis based on k-means are also performed.",Big data analytics cyber security network attacks duplicate data missing data masquerade
Cyber Security,"Federated Deep Learning for Cyber Security in the Internet of Things: Concepts, Applications, and Experimental Analysis","n this article, we present a comprehensive study with an experimental analysis of federated deep learning approaches for cyber security in the Internet of Things (IoT) applications. Specifically, we first provide a review of the federated learning-based security and privacy systems for several types of IoT applications, including, Industrial IoT, Edge Computing, Internet of Drones, Internet of Healthcare Things, Internet of Vehicles, etc. Second, the use of federated learning with blockchain and malware/intrusion detection systems for IoT applications is discussed. Then, we review the vulnerabilities in federated learning-based security and privacy systems. Finally, we provide an experimental analysis of federated deep learning with three deep learning approaches, namely, Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and Deep Neural Network (DNN). For each deep learning model, we study the performance of centralized and federated learning under three new real IoT traffic datasets, namely, the Bot-IoT dataset, the MQTTset dataset, and the TON_IoT dataset. The goal of this article is to provide important information on federated deep learning approaches with emerging technologies for cyber security. In addition, it demonstrates that federated deep learning approaches outperform the classic/centralized versions of machine learning (non-federated learning) in assuring the privacy of IoT device data and provide the higher accuracy in detecting attacks.","Federated learning, intrusion detection, deep learning, cyber security, the IoT, blockchain"
Cyber Security,Cyber-Attack Detection and Cyber-Security Enhancement in Smart DC-Microgrid Based on Blockchain Technology and Hilbert Huang Transform,"Due to the simultaneous development of DC-microgrids (DC-MGs) and the use of intelligent control, monitoring and operation methods, as well as their structure, these networks can be threatened by various cyber-attacks. Overall, a typical smart DC-MG includes battery, supercapacitors and power electronic devices, fuel cell, solar Photovoltaic (PV) systems, and loads such as smart homes, plug-in hybrid electrical vehicle (PHEV), smart sensors and network communication like fiber cable or wireless to send and receive data. Given these issues, cyber-attack detection and securing data exchanged in smart DC-MGs like CPS has been considered by experts as a significant subject in recent years. In this study, in order to detect false data injection attacks (FDIAs) in a MG system, Hilbert-Huang transform methodology along with blockchainbased ledger technology is used for enhancing the security in the smart DC-MGs with analyzing the voltage and current signals in smart sensors and controllers by extracting the signal details. Results of simulation on the different cases are considered with the objective of verifying the efficacy of the proposed model. The results offer that the suggested model can provide a more precise and robust detection mechanism against FDIA and improve the security of data exchanging in a smart DC-MG.","Smart DC-microgrid, Hilbert-Huang Transform, false data injection attack, data exchanging, blockchain."
Cyber Security,Machine learning methods for cyber security intrusion detection: Datasets and comparative study,"The increase in internet usage brings security problems with it. Malicious software can affect the operation of the systems and disrupt data confidentiality due to the security gaps in the systems. Intrusion Detection Systems (IDS) have been developed to detect and report attacks. In order to develop IDS systems, artificial intelligence-based approaches have been used more frequently. In this study, literature studies using CSE-CIC IDS-2018, UNSW-NB15, ISCX-2012, NSL-KDD and CIDDS-001 data sets, which are widely used to develop IDS systems, are reviewed in detail. In addition, max-min normalization was performed on these data sets and classification was made with support vector machine (SVM), K-Nearest neighbor (KNN), Decision Tree (DT) algorithms, which are among the classical machine learning approaches. As a result, more successful results have been obtained in some of the studies given in the literature. The study is thought to be useful for developing IDS systems on the basis of artificial intelligence with approaches such as machine learning.",IDS KNN SVM DT Machine learning Cyber security
Cyber Security,Cyber Security in IoT-Based Cloud Computing: A Comprehensive Survey,"Cloud computing provides the flexible architecture where data and resources are dispersed at various locations and are accessible from various industrial environments. Cloud computing has changed the using, storing, and sharing of resources such as data, services, and applications for industrial applications. During the last decade, industries have rapidly switched to cloud computing for having more comprehensive access, reduced cost, and increased performance. In addition, significant improvement has been observed in the internet of things (IoT) with the integration of cloud computing. However, this rapid transition into the cloud raised various security issues and concerns. Traditional security solutions are not directly applicable and sometimes ineffective for cloud-based systems. Cloud platforms’ challenges and security concerns have been addressed during the last three years, despite the successive use and proliferation of multifaceted cyber weapons. The rapid evolution of deep learning (DL) in the artificial intelligence (AI) domain has brought many benefits that can be utilized to address industrial security issues in the cloud. The findings of the proposed research include the following: we present a comprehensive survey of enabling cloud-based IoT architecture, services, configurations, and security models; the classification of cloud security concerns in IoT into four major categories (data, network and service, applications, and people-related security issues), which are discussed in detail; we identify and inspect the latest advancements in cloud-based IoT attacks; we identify, discuss, and analyze significant security issues in each category and present the limitations from a general, artificial intelligence and deep learning perspective; we provide the technological challenges identified in the literature and then identify significant research gaps in the IoT-based cloud infrastructure to highlight future research directions to blend cybersecurity in cloud.",cloud computing; IoT security; cybersecurity; cloud configuration; deep learning; machine learning; attacks; attack prevention; platform as a service (PaaS); infrastructure as a service (IaaS); software as a service (SaaS); development as a service (DaaS); forensic as a service (FaaS)
Cyber Security,A Blockchain-Based Deep Learning Approach for Cyber Security in Next Generation Industrial Cyber-Physical Systems,"With the recent development of Internet of Things (IoT) in the next generation cyber-physical system (CPS) such as autonomous driving, there is a significant requirement of big data analysis with high accuracy and low latency. For efficient big data analysis, deep learning (DL) supports strong analytic capability; it has been applied at the cloud and edge layers by extensive research to provide accurate data analysis at low latency. However, existing researches failed to address certain challenges, such as centralized control, adversarial attacks, security, and privacy. To this end, we propose DeepBlockIoTNet, a secure DL approach with blockchain for the IoT network wherein the DL operation is carried out among the edge nodes at the edge layer in a decentralized, secure manner. The blockchain provides a secure DL operation and removes the control from a centralized authority. The experimental evaluation demonstrates that the proposed approach supports higher accuracy.","Blockchain, cyber-physical systems (CPS), deep learning (DL), Internet of Things (IoT), security and privacy"
Cyber Security,"Smart city and cyber-security; technologies used, leading challenges and future recommendations","Today, some cities around the world have tended to use new technologies and become smart city. New technologies improve the quality of citizens’ life. However, the use of any technology raises new issues and challenges. In a smart city, the vulnerable action of an individual or organization can put the entire city at risk. Due to the reliance of various components of smart cities on information and communication technology, cyber-security challenges (such as information leakage and malicious cyber-attacks) in this field affect smart cities behavior. Therefore, in order to respond to the enthusiastic acceptance of global smart city technologies, cyber security must develop in same direction. The aim of this paper is survey and discus on explanation of cyber security, smart cities, and survey of available relevant literature on security in that technology. For this purpose, the present study focuses on the four main components of a smart city, i.e. smart grid, Smart building, Smart transportation system, and Smart healthcare. In particular, summary of two deep learning method and cyber-security programs as well as technology correlation in smart cities are discussed. Furthermore, effective functional solutions in maintaining cyber-security and user privacy in smart cities are explained. The next progress trends of smart city with cyber security are described. Solutions need to be devised to address each of the security issues. The research in this study showed that meeting these challenges depends on the hard work of governments, developers of equipment and software and companies providing IT security services. In addition, designing flexible systems with high information protection capabilities is essential to prevent serious security incidents as these incidents can lead to disastrous financial, data, credit and loss of public trust.",Smart city Cyber-attacks Cyber-security Challenges and recommendations Deep learning
Cyber Security,A Systemic IoT-Fog-Cloud Architecture for Big-Data Analytics and Cyber Security Systems: A Review of Fog Computing,"—With the rapid growth of the Internet of Things (IoT), current Cloud systems face various drawbacks such as lack of mobility support, location-awareness, geo-distribution, high latency, as well as cyber threats. Fog/Edge computing has been proposed for addressing some of the drawbacks, as it enables computing resources at the network’s edges and it locally offers big-data analytics rather than transmitting them to the Cloud. The Fog is defined as a Cloud-like system having similar functions, including software-, platform- and infrastructure-as services. The deployment of Fog applications faces various security issues related to virtualisation, network monitoring, data protection and attack detection. This paper proposes a systemic IoT-Fog-Cloud architecture that clarifies the interactions between the three layers of IoT, Fog and Cloud for effectively implementing bigdata analytics and cyber security applications. It also reviews security challenges, solutions and future research directions in the architecture","Fog/Edge Computing, Cloud Computing, Internet of Things (IoT), Cyber-attacks, Challenges, Solutions"
Cyber Security, Cyber Security Threats on Digital Banking, "Digital banking is the new form of banking that involves using the internet and mobile applications and excludes the use of pen and paper. One of the main issues that are associated with the form of banking is the presence of several forms of security risks. These risks are caused due to criminal activities of hackers and fraudsters who aim to steal people's money. Therefore an efficient security system that involves multiple verifications authentication processes and data encryption are needed to combat such a threat. There has been much other work about this topic by other authors. By analyzing the finding from all of these sources the STUDY has found that cyber security threats are a major problem in digital banking. Most people are not even aware or concerned about this matter. The research has used a theoretical analysis method involving secondary information sources. The research has also been able to bring out some hypotheses about this topic which it has also been able to support by using the statements and graphical charts given by other authors in their previous works about this topic. The research topic is interesting and can be used to do further research in the future.", Cyber Security Threats Digital Banking
Cyber Security, Deep Learning Approach to DGA Classification for Effective Cyber Security,"- In recent years, invaders are increasing rapidly in an internet world. Generally, in order to detect the anonymous attackers algorithm needs more number of features. Many algorithms fail in the efficiency of detection malicious code. Immediately this codes will not infect the system; it will attack server after communicate later. Our research focuses on analyzing the traffic of botnets for the domain name determination to the IP address of the server. This botnet creates the domain name differently. Many domains are generated by attackers and create the huge Domain Name System (DNS) traffic. In this research paper, uses both public and real time environments datasets to detect the text features as well as knowledge based feature extraction. The classifying of Domain Generation Algorithm (DGA) generated malicious domains randomly making the efficiency down in many algorithms which were used preprocessing without proper feature extraction. Effectively, our proposed algorithm is used to detect DGA which generates malicious domains randomly. This effective detection of our proposed algorithm performs with text based label prediction and additional features for extraction to improve the efficiency of the model. Our proposed model achieved 94.9% accuracy for DGA classification with help of additional feature extraction and knowledge based extraction in the deep learning architecture."," deep learning, Cyber security, Domain Generation Algorithm"
Cyber Security,An Analysis of IoT Cyber Security Driven by Machine Learning,"Since the beginning of the Internet of Things (IoT), the number of IoT devices connected to the Internet has grown rapidly. However, many IoT devices lack the security standards that non-IoT devices have. This means that billions of smart devices could be used as part of a botnet attack or point of entry into a secured network. The potential to exploit an IoT device makes the search to find suitable IoT security measures extremely important. In order to fill this need, this study explores the use of machine learning in IoT security measures. Upon reviewing recent developments of machine learning in IoT security, it was found that the methods with the highest threat detection accuracy utilized the random forest and K-nearest neighbor algorithms and the most efficient methods utilized software-defined networks (SDN) and the fog layer of networks. In addition, the methods which determine the type of IoT device one is when it connects to a network primarily used the random forest algorithm. This study will take an in-depth look at the use of machine learning algorithms to detect malicious and anomalous data within IoT systems.",Internet of Things Machine learning Cyber security Device type identification Anomaly detection Botnet attacks
Cyber Security,Assessing MITRE ATT&CK Risk Using a Cyber-Security Culture Framework,"The MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) Framework provides a rich and actionable repository of adversarial tactics, techniques, and procedures. Its innovative approach has been broadly welcomed by both vendors and enterprise customers in the industry. Its usage extends from adversary emulation, red teaming, behavioral analytics development to a defensive gap and SOC (Security Operations Center) maturity assessment. While extensive research has been done on analyzing specific attacks or specific organizational culture and human behavior factors leading to such attacks, a holistic view on the association of both is currently missing. In this paper, we present our research results on associating a comprehensive set of organizational and individual culture factors (as described on our developed cyber-security culture framework) with security vulnerabilities mapped to specific adversary behavior and patterns utilizing the MITRE ATT&CK framework. Thus, exploiting MITRE ATT&CK’s possibilities towards a scientific direction that has not yet been explored: security assessment and defensive design, a step prior to its current application domain. The suggested cyber-security culture framework was originally designed to aim at critical infrastructures and, more specifically, the energy sector. Organizations of these domains exhibit a co-existence and strong interaction of the IT (Information Technology) and OT (Operational Technology) networks. As a result, we emphasize our scientific effort on the hybrid MITRE ATT&CK for Enterprise and ICS (Industrial Control Systems) model as a broader and more holistic approach. The results of our research can be utilized in an extensive set of applications, including the efficient organization of security procedures as well as enhancing security readiness evaluation results by providing more insights into imminent threats and security risks.",cyber-security culture framework; MITRE ATT&CK matrix; security assessment; detection; mitigation techniques
Cyber Security,Investigation of Cyber-Security and Cyber-Crimes in Oil and Gas Sectors Using the Innovative Structures of Complex Intuitionistic Fuzzy Relations,"Recently, there has been enormous development due to advancements in technology. Industries and enterprises are moving towards a digital system, and the oil and gas industries are no exception. There are several threats and risks in digital systems, which are controlled through cyber-security. For the first time in the theory of fuzzy sets, this research analyzes the relationships between cyber-security and cyber-crimes in the oil and gas sectors. The novel concepts of complex intuitionistic fuzzy relations (CIFRs) are introduced. Moreover, the types of CIFRs are defined and their properties are discussed. In addition, an application is presented that uses the Hasse diagram to make a decision regarding the most suitable cyber-security techniques to implement in an industry. Furthermore, the omnipotence of the proposed methods is explained by a comparative study.",block chain; Cartesian product; complex intuitionistic fuzzy relation; complex intuitionistic fuzzy set; cyber-security; Hasse diagram; oil and gas industry
Cyber Security,Internet of Things Meet Internet of Threats: New Concern Cyber Security Issues of Critical Cyber Infrastructure,": As a new area of technology, the Internet of Things (IoT) is a flagship and promising paradigm for innovating society. However, IoT-based critical infrastructures are an appealing target for cybercriminals. Such distinctive infrastructures are increasingly sensitive to cyber vulnerabilities and subject to many cyberattacks. Thus, protecting these infrastructures is a significant issue for organizations and nations. In this context, raising the cybersecurity posture of critical cyber infrastructures is an extremely urgent international issue. In addition, with the rapid development of adversarial techniques, current cyber threats have become more sophisticated, complicated, advanced and persistent. Thus, given these factors, prior to implementing efficient and resilient cybersecurity countermeasures, identification and in-depth mapping of cyber threats is an important step that is generally overlooked. Therefore, to solve cybersecurity challenges, this study presents a critical analysis of the most recent cybersecurity issues for IoT-based critical infrastructures. We then discuss potential cyber threats and cyber vulnerabilities and the main exploitation strategies adopted by cybercriminals. Further, we provide a taxonomy of cyberattacks that may affect critical cyber infrastructures. Finally, we present security requirements and some realistic recommendations to enhance cybersecurity solutions.",critical cyber infrastructure; cyber security; cyber attacks; Internet of Things (IoT)
Cyber Security,Security Control for T–S Fuzzy Systems With Adaptive Event-Triggered Mechanism and Multiple Cyber-Attacks,"This article focuses on the security control for Takagi–Sugeno (T–S) fuzzy systems with adaptive event-triggered mechanism (AETM) and multiple cyber-attacks, which include deception attacks and denial-of-service (DoS) attacks. A multiple cyber-attacks model is first established for T–S fuzzy systems by considering deception attacks and DoS attacks at the same time. An AETM is introduced to relieve the network load, where the threshold of event-triggering condition can be adaptively adjusted while preserving the system performance. Then a novel mathematical model for T–S fuzzy systems with multiple cyber-attacks and AETM is proposed first. Based on the built model, sufficient conditions to guarantee the exponentially mean square stability of the system are achieved by utilizing the Lyapunov stability theory. Moreover, the controller gains are derived with the help of a linear matrix inequality technique. Finally, simulated examples are presented for illustrating the effectiveness of the proposed method.","Adaptive event-triggered mechanism (AETM), multiple cyber-attacks, security control, Takagi–Sugeno (T–S) fuzzy systems."
Cyber Security,Resilient Machine Learning for Networked Cyber Physical Systems: A Survey for Machine Learning Security to Securing Machine Learning for CPS,"Cyber Physical Systems (CPS) are characterized by their ability to integrate the physical and information or cyber worlds. Their deployment in critical infrastructure have demonstrated a potential to transform the world. However, harnessing this potential is limited by their critical nature and the far reaching effects of cyber attacks on human, infrastructure and the environment. An attraction for cyber concerns in CPS rises from the process of sending information from sensors to actuators over the wireless communication medium, thereby widening the attack surface. Traditionally, CPS security has been investigated from the perspective of preventing intruders from gaining access to the system using cryptography and other access control techniques. Most research work have therefore focused on the detection of attacks in CPS. However, in a world of increasing adversaries, it is becoming more difficult to totally prevent CPS from adversarial attacks, hence the need to focus on making CPS resilient. Resilient CPS are designed to withstand disruptions and remain functional despite the operation of adversaries. One of the dominant methodologies explored for building resilient CPS is dependent on machine learning (ML) algorithms. However, rising from recent research in adversarial ML, we posit that ML algorithms for securing CPS must themselves be resilient. This paper is therefore aimed at comprehensively surveying the interactions between resilient CPS using ML and resilient ML when applied in CPS. The paper concludes with a number of research trends and promising future research directions. Furthermore, with this paper, readers can have a thorough understanding of recent advances on ML-based security and securing ML for CPS and countermeasures, as well as research trends in this active research area.","Adversarial attacks, Cybersecurity, Machine Learning, Resiliency in Cyber Physical Systems"
Cyber Security,Event-Triggered Security Output Feedback Control for Networked Interconnected Systems Subject to Cyber-Attacks,"This article studies the security of networked interconnected systems (NISs) subject to cyber-attacks based on a new event-triggered mechanism (ETM). NISs with spatially distributed subsystems are vulnerable to cyber-attacks. With a new concept of security control, attention is focused on designing a novel ETM together with a decentralized output feedback control (DOFC) scheme such that the NIS subject to cyber-attacks is stable in secure sense. Under the proposed ETM, the average data-releasing rate over the whole operating period can be extremely decreased, thereby reducing the burden of network bandwidth, computation, and battery-supply. Moreover, during the system with external disturbance or attack on the communication network, more transmission-events can be generated than other periods. As a result, the desired control performance can be achieved. By using stochastic analysis techniques and Lyapunov stability theory, sufficient conditions are derived to obtain both the controller gains and the parameters of the ETM. Numerical simulation of chemical reactor systems is given to illustrate the advantages and effectiveness of the proposed theories and design techniques.","Cyber attacks, event-triggered control, networked interconnected control systems."
Data Mining,A Data Mining Approach for Identifying Predictors of Student Retention from Sophomore to Junior Year," Student retention is an important issue for all university policy makers due to the potential negative impact on the image of the university and the career path of the dropouts. Although this issue has been thoroughly studied by many institutional researchers using parametric techniques, such as regression analysis and logit modeling, this article attempts to bring in a new perspective by exploring the issue with the use of three data mining techniques, namely, classification trees, multivariate adaptive regression splines (MARS), and neural networks. Data mining procedures identify transferred hours, residency, and ethnicity as crucial factors to retention. Carrying transferred hours into the university implies that the students have taken college level classes somewhere else, suggesting that they are more academically prepared for university study than those who have no transferred hours. Although residency was found to be a crucial predictor to retention, one should not go too far as to interpret this finding that retention is affected by proximity to the university location. Instead, this is a typical example of Simpson’s Paradox. The geographical information system analysis indicates that non-residents from the east coast tend to be more persistent in enrollment than their west coast schoolmates.","Classification trees, cross-validation, data mining, exploratory data analysis, MARS, neural networks, resampling, under-determination of theory by data."
Data Mining,CRISP-DM Twenty Years Later: From Data Mining Processes to Data Science Trajectories,"CRISP-DM(CRoss-Industry Standard Process for Data Mining) has its origins in the second half of the nineties and is thus about two decades old. According to many surveys and user polls it is still the de facto standard for developing data mining and knowledge discovery projects. However, undoubtedly the field has moved on considerably in twenty years, with data science now the leading term being favoured over data mining. In this paper we investigate whether, and in what contexts, CRISP-DM is still fit for purpose for data science projects. We argue that if the project is goal-directed and process-driven the process model view still largely holds. On the other hand, when data science projects become more exploratory the paths that the project can take become more varied, and a more flexible model is called for. We suggest what the outlines of such a trajectory-based model might look like and how it can be used to categorise data science projects (goal-directed, exploratory or data management). We examine seven real-life exemplars where exploratory activities play an important role and compare them against 51 use cases extracted from the NIST Big Data Public Working Group. We anticipate this categorisation can help project planning in terms of time and cost characteristics.","Data science trajectories, data mining, knowledge discovery process, data-driven methodologies"
Data Mining,Improving the Prediction of Heart Failure Patients’ Survival Using SMOTE and Effective Data Mining Techniques,"Cardiovascular disease is a substantial cause of mortality and morbidity in the world. In clinical data analytics, it is a great challenge to predict heart disease survivor. Data mining transforms huge amounts of raw data generated by the health industry into useful information that can help in making informed decisions. Various studies proved that significant features play a key role in improving performance of machine learning models. This study analyzes the heart failure survivors from the dataset of 299 patients admitted in hospital. The aim is to find significant features and effective data mining techniques that can boost the accuracy of cardiovascular patient’s survivor prediction. To predict patient’s survival, this study employs nine classification models: Decision Tree (DT), Adaptive boosting classifier (AdaBoost), Logistic Regression (LR), Stochastic Gradient classifier (SGD), Random Forest (RF), Gradient Boosting classifier (GBM), Extra Tree Classifier (ETC), Gaussian Naive Bayes classifier (G-NB) and Support Vector Machine (SVM). The imbalance class problem is handled by Synthetic Minority Oversampling Technique (SMOTE). Furthermore, machine learning models are trained on the highest ranked features selected by RF. The results are compared with those provided by machine learning algorithms using full set of features. Experimental results demonstrate that ETC outperforms other models and achieves 0.9262 accuracy value with SMOTE in prediction of heart patient’s survival.","Data mining, heart disease classification, machine learning, cardiovascular disease, feature selection, SMOTE."
Data Mining,Machine learning and data mining in manufacturing,"Manufacturing organizations need to use different kinds of techniques and tools in order to fulfill their foundation goals. In this aspect, using machine learning (ML) and data mining (DM) techniques and tools could be very helpful for dealing with challenges in manufacturing. Therefore, in this paper, a comprehensive literature review is presented to provide an overview of how machine learning techniques can be applied to realize manufacturing mechanisms with intelligent actions. Furthermore, it points to several significant research questions that are unanswered in the recent literature having the same target. Our survey aims to provide researchers with a solid understanding of the main approaches and algorithms used to improve manufacturing processes over the past two decades. It presents the previous ML studies and recent advances in manufacturing by grouping them under four main subjects: scheduling, monitoring, quality, and failure. It comprehensively discusses existing solutions in manufacturing according to various aspects, including tasks (i.e., clustering, classification, regression), algorithms (i.e., support vector machine, neural network), learning types (i.e., ensemble learning, deep learning), and performance metrics (i.e., accuracy, mean absolute error). Furthermore, the main steps of knowledge discovery in databases (KDD) process to be followed in manufacturing applications are explained in detail. In addition, some statistics about the current state are also given from different perspectives. Besides, it explains the advantages of using machine learning techniques in manufacturing, expresses the ways to overcome certain challenges, and offers some possible further research directions.",Machine learning Data mining Manufacturing Classification Clustering
Data Mining,"Data mining in clinical big data: the frequently used databases, steps, and methodological models","Many high quality studies have emerged from public databases, such as Surveillance, Epidemiology, and End Results (SEER), National Health and Nutrition Examination Survey (NHANES), The Cancer Genome Atlas (TCGA), and Medical Information Mart for Intensive Care (MIMIC); however, these data are often characterized by a high degree of dimensional heterogeneity, timeliness, scarcity, irregularity, and other characteristics, resulting in the value of these data not being fully utilized. Data-mining technology has been a frontier field in medical research, as it demonstrates excellent performance in evaluating patient risks and assisting clinical decision-making in building disease-prediction models. Therefore, data mining has unique advantages in clinical big-data research, especially in large-scale medical public databases. This article introduced the main medical public database and described the steps, tasks, and models of data mining in simple language. Additionally, we described data-mining methods along with their practical applications. The goal of this work was to aid clinical researchers in gaining a clear and intuitive understanding of the application of data-mining technology on clinical big-data in order to promote the production of research results that are beneficial to doctors and patients.","Clinical big data, Data mining, Machine learning, Medical public database, SEER, NHANES, TCGA, MIMIC"
Data Mining,Detecting Financial Fraud Using Data Mining Techniques: A Decade Review from 2004 to 2015,"Objective: Financial fraud has been a big concern for many organizations across industries; billions of dollars are lost yearly because of this fraud. So businesses employ data mining techniques to address this continued and growing problem. This paper aims to review research studies conducted to detect financial fraud using data mining tools within one decade and communicate the current trends to academic scholars and industry practitioners. Method: Various combinations of keywords were used to identify the pertinent articles. The majority of the articles retrieved from Science Direct but the search spanned other online databases (e.g., Emerald, Elsevier, World Scientific, IEEE, and Routledge - Taylor and Francis Group). Our search yielded a sample of 65 relevant articles (58 peer-reviewed journal articles with 7 conference papers). Onefifth of the articles was found in Expert Systems with Applications (ESA) while about one-tenth found in Decision Support Systems (DSS). Results: 41 data mining techniques were used to detect fraud across different financial applications such as health insurance and credit card. Logistic regression model appeared to be the leading data mining tool in detecting financial fraud with a 13% of usage.In general, supervised learning tool have been used more frequently than the unsupervised ones. Financial statement fraud and bank fraud are the two largest financial applications being investigated in this area – about 63%, which corresponds to 41 articles out of the 65 reviewed articles. Also, the two primary journal outlets for this topic are ESA and DSS. Conclusion: This review provides a fast and easy-to-use source for both researchers and professionals, classifies financial fraud applications into a highlevel and detailed-level framework, shows the most significant data mining techniques in this domain, and reveals the most countries exposed to financial fraud.","Financial fraud, fraud detection, data mining techniques, literature review."
Data Mining,A Comprehensive Survey of Big Data Mining Approaches in Cloud Systems,"Cloud computing, data mining, and big online data are discussed in this paper as hybridization possibilities. The method of analyzing and visualizing vast volumes of data is known as the visualization of data mining. The effect of computing conventions and algorithms on detailed storage and data communication requirements has been studied. When researching these approaches to data storage in big data, the data analytical viewpoint is often explored. These terminology and aspects have been used to address methodological development as well as problem statements. This will assist in the investigation of computational capacity as well as new knowledge in this area. The patterns of using big data were compared in many articles. In this paper, we research Big Data Mining Approaches in Cloud Systems and address cloudcompatible problems and computing techniques to promote Big Data Mining in Cloud Systems.","Big Data, Data Computing, Big Data Mining, Cloud Computing"
Data Mining,A Self Monitoring and Analyzing System for Solar Power Station using IoT and Data Mining Algorithms,"Renewable energy sources are gaining a significant research attention due to their economical and sustainable characteristics. In particular, solar power stations are considered as one of the renewable energy systems that may be used in different locations since it requires a lower installation cost and maintenance than conventional systems, despite the fact that they require less area. In most of the small generating stations, space occupancy is controlled by placing the equipment on an open terrace. However, for large-scale power generating stations, acres of land are required for installation. Human employers face a challenging task in maintaining such a large area of power station. Through IoT and data mining techniques, the proposed algorithm would aid human employers in detecting the regularity of power generation and failure or defective regions in solar power systems. This allows performing a quick action for the fault rectification process, resulting in increased generating station efficiency. ","Solar panel maintenance, maximum power generation, IoT, data mining, solar panel"
Data Mining,Fischer Linear Discrimination and Quadratic Discrimination Analysis-Based Data Mining Technique for Internet of Things Framework for Healthcare,"The internet of reality or augmented reality has been considered a breakthrough and an outstanding critical mutation with an emphasis on data mining leading to dismantling of some of its assumptions among several of its stakeholders. In this work, we study the pillars of these technologies connected to web usage as the Internet of things (IoT) system's healthcare infrastructure. We used several data mining techniques to evaluate the online advertisement data set, which can be categorized as high dimensional with 1,553 attributes, and the imbalanced data set, which automatically simulates an IoT discrimination problem. The proposed methodology applies Fischer linear discrimination analysis (FLDA) and quadratic discrimination analysis (QDA) within random projection (RP) filters to compare our runtime and accuracy with support vector machine (SVM), K-nearest neighbor (KNN), and Multilayer perceptron (MLP) in IoT-based systems. Finally, the impact on number of projections was practically experimented, and the sensitivity of both FLDA and QDA with regard to precision and runtime was found to be challenging. The modeling results show not only improved accuracy, but also runtime improvements. When compared with SVM, KNN, and MLP in QDA and FLDA, runtime shortens by 20 times in our chosen data set simulated for a healthcare framework. The RP filtering in the preprocessing stage of the attribute selection, fulfilling the model's runtime, is a standpoint in the IoT industry. Index Terms: Data Mining, Random Projection, Fischer Linear Discriminant Analysis, Online Advertisement Dataset, Quadratic Discriminant Analysis, Feature Selection, Internet of Things.",Fischer linear discriminant analysis; Internet of Things—IoT; data mining; feature exaction and selection; healthcare applications; quadratic discriminant analysis (QDA).
Data Mining,Intelligent Recommendation System Based on Mathematical Modeling in Personalized Data Mining,"With the advent of the era of big data, data mining has become one of the key technologies in the field of research and business. In order to improve the efficiency of data mining, this paper studies data mining based on the intelligent recommendation system. Firstly, this paper makes mathematical modeling of the intelligent recommendation system based on association rules. After analyzing the requirements of the intelligent recommendation system, Java 2 Platform, Enterprise Edition, technology is used to divide the system architecture into the presentation layer, business logic layer, and data layer. Recommendation module is divided into three substages: data representation, model learning, and recommendation engine. *en, the fuzzy clustering algorithm is used to optimize the system. After the system is built, the performance of the system is evaluated, and the evaluation indexes include accuracy, coverage, and response time. Finally, the system is put into a trial operation of an e-commerce platform. *e click-through rate and purchase conversion rate of recommended products before and after the operation are compared, and a questionnaire survey is randomly launched to the platform users to analyze the user satisfaction. *e experimental data show that the MAE of this system is the lowest, maintained at about 0.73, and its accuracy is the highest; before the recommended threshold exceeds 0.5, the average coverage rate of this system is the highest: 0.75; in Q1–Q5 subsets, the shortest response time of the system is 0.2 s. Before and after the operation of the system, the average click-through rate increased by 11.04%, and the average purchase rate increased by 9.35%. Among the 1216 users, 43% of the users were satisfied with 4 and 9% with 1. *is shows that the system algorithm convergence speed is fast; it can recommend products more in line with user needs and interests and promote higher click-through rate and purchase rate, but user satisfaction can be further improved.",data mining recommendation system fuzzy clustering mathematical modeling
Data Mining,Early warning of enterprise finance risk of big data mining in internet of things based on fuzzy association rules,"As the big data, Internet of Things, cloud computing, and other ideas and technologies are integrated into social life, the big data technology can improve the corporate financial data processing. At the same time, with the fiercer competition between enterprises, investors and enterprises have paid more attention to the role of financial crisis warning in corporate management. The work selected the multiple financial indicators based on big data mining in Internet of Things. The rules between all financial indicators were found to choose more representative financial risk indicators. Then the frequent fuzzy option set was determined by FCM (fuzzy cluster method), parallel rules, and parallel mining algorithm, thus obtaining the fuzzy association rules that satisfy the minimum fuzzy credibility. Finally, the relevant data of listed companies were selected to analyze the corporate financial risks, which verified the method proposed in the work.",Big data  Internet of Things  Financial risk  Fuzzy clustering  Data mining
Data Mining,A BIM-data mining integrated digital twin framework for advanced project management,"With the focus of smart construction project management, this paper presents a closed-loop digital twin framework under the integration of Building Information Modeling (BIM), Internet of Things (IoT), and data mining (DM) techniques. To be specific, IoT connects the physical and cyber world to capture real-time data for modeling and analyzing, and data mining methods incorporated in the virtual model aim to discover hidden knowledge in collected data. The proposed digital twin has been verified in a practical BIM-based project. Based on large inspection data from IoT devices, the 4D visualization and task-centered or worker-centered process model are built as the virtual model to simulate both the task execution and worker cooperation. Then, the high-fidelity virtual model is investigated by process mining and time series analysis. Results show that possible bottlenecks in the current process can be foreseen using the fuzzy miner, while the number of finished tasks in the next phase can be predicted by the multivariate autoregressive integrated moving average (ARIMAX) model. Consequently, tactic decision-making can realize to not only prevent possible failure in advance, but also arrange work and staffing reasonably to make the process adapt to changeable conditions. In short, the significance of this paper is to build a data-driven digital twin framework integrating with BIM, IoT, and data mining for advanced project management, which can facilitate data communication and exploration to better understand, predict, and optimize the physical construction operations. In future works, more complex cases with multiple data streams will be used to test the developed framework, and more detailed interpretations with the actual observations of construction activities will be given.",Digital twinBuilding information modeling (BIM)Process miningTime series analysis
Data Mining,Data Mining for the Internet of Things: Literature Review and Challenges,"The huge data generate by the Internet of Things (IOT) are measured of high business worth, and data mining algorithms can be applied to IOT to take out hidden information from data. In this paper, we give a methodical way to review data mining in knowledge, technique and application view, together with classification, clustering, association analysis and time series analysis, outlier analysis. And the latest application luggage is also surveyed. As more and more devices connected to IOT, huge volume of data should be analyzed, the latest algorithms should be customized to apply to big data. We reviewed these algorithms and discussed challenges and open research issues. At last a suggested big data mining system is proposed.","Internet of things, Classification, clustering, Association analysis."
Data Mining,Applying data mining techniques to explore user behaviors and watching video patterns in converged IT environments,"Comfortable leisure and entertainment is expected through multimedia. Web multimedia systems provide diversified multimedia interactions, for example, sharing knowledge, experience and information, and establishing common watching habits. People use information technology (IT) systems to watch multimedia videos and to perform interactive functions. Moreover, IT systems enhance multimedia interactions between users. To explore user behaviors in viewing multimedia videos by key points in time, multimedia video watching patterns are analyzed by data mining techniques. Data mining methods were used to analyze users’ video watching patterns in converged IT environments. After the experiment, we recorded the processes of clicking the Web multimedia video player. The system logs of using the video player are classified into four variables, playing time, active playing time, played amount, and actively played amount. To explore the four variables, we apply the k-means clustering technique to organize the similar playing behavior patterns of the users into three categories: actively engaged users, watching engaged users, and long engaged users. Finally, we applied statistical analysis methods to compare the three categories of users’ watching behaviors. The results showed that there were significant differences among the three categories.",Data mining techniques · User behaviors · Watching video patterns · Converged IT environments
Data Mining,A Simulation-driven Methodology for IoT Data Mining Based on Edge Computing,"With the ever-increasing diffusion of smart devices and Internet of Things (IoT) applications, a completely new set of challenges have been added to the Data Mining domain. Edge Mining and Cloud Mining refer to Data Mining tasks aimed at IoT scenarios and performed according to, respectively, Cloud or Edge computing principles. Given the orthogonality and interdependence among the Data Mining task goals (e.g., accuracy, support, precision), the requirements of IoT applications (mainly bandwidth, energy saving, responsiveness, privacy preserving, and security) and the features of Edge/Cloud deployments (de-centralization, reliability, and ease of management), we propose EdgeMiningSim, a simulation-driven methodology inspired by software engineering principles for enabling IoT Data Mining. Such a methodology drives the domain experts in disclosing actionable knowledge, namely descriptive or predictive models for taking effective actions in the constrained and dynamic IoT scenario. A Smart Monitoring application is instantiated as a case study, aiming to exemplify the EdgeMiningSim approach and to show its benefits in effectively facing all those multifaceted aspects that simultaneously impact on IoT Data Mining.","Data mining, Internet of Things, cloud computing, edge computing computer system organisation"
Data Mining,Machine learning and data mining in manufacturing, "Manufacturing organizations need to use different kinds of techniques and tools in order to fulfill their foundation goals. In this aspect using machine learning (ML) and data mining (DM) techniques and tools could be very helpful for dealing with challenges in manufacturing. Therefore in this paper a comprehensive literature review is presented to provide an overview of how machine learning techniques can be applied to realize manufacturing mechanisms with intelligent actions. Furthermore it points to several significant research questions that are unanswered in the recent literature having the same target. Our survey aims to provide researchers with a solid understanding of the main approaches and algorithms used to improve manufacturing processes over the past two decades. It presents the previous ML studies and recent advances in manufacturing by grouping them under four main subjects: scheduling monitoring quality and failure. It comprehensively discusses existing solutions in manufacturing according to various aspects including tasks (i.e. clustering classification regression) algorithms (i.e. support vector machine neural network) learning types (i.e. ensemble learning deep learning) and performance metrics (i.e. accuracy mean absolute error). Furthermore the main steps of knowledge discovery in databases (KDD) process to be followed in manufacturing applications are explained in detail. In addition some statistics about the current state are also given from different perspectives. Besides it explains the advantages of using machine learning techniques in manufacturing expresses the ways to overcome certain challenges and offers some possible further research directions.","Machine learning Data mining Manufacturing Classification Clustering"
Data Mining,Data Mining Framework for Nutrition Ranking: Methodology: SPSS Modeller,The goal of this research is to use the technology of Data Mining in a dataset for a ranking of three diets on the respondents and investigate such tools advantages and limitations such as large amount of manipulation before analysis replications with the same results from the analysis bias. Here we can see the ethical consequences of such programs in details.,"Data Science, Nutrition Assessment, Clustering Analysis"
Data Mining,Sports decision-making model based on data mining and neural network,"The sports decision-making system is affected by many factors, and the sports decision-making system itself is a complex decision-making system, including multiple micro-systems. In order to construct a more scientific sports decision-making model, this paper builds a sports decision-making model based on data mining and neural network based on data mining technology and neural network algorithms. Moreover, based on the analysis of system theory, stakeholder theory and multi-objective decision-making theory, this paper provides a theoretical basis for the study of multi-objective decision-making problems in sports events. In addition, this paper discusses the starting point of decision-making and the scope of research from the basic concepts of sports decision-making and analyzes the multi-objective decision-making system of sports decision-making. At the same time, on this basis, this paper designs a multi-objective decision-making model for sports events, and finally conducts empirical research based on the designed model. Through empirical analysis and simulation research, it can be known that the combined model constructed in this paper performs well and has certain practical effects.",Data mining  Neural network  Machine learning  Sports decision-making
Data Mining,Knowledge Discovery for Higher Education Student Retention Based on Data Mining: Machine Learning Algorithms and Case Study in Chile,"Data mining is employed to extract useful information and to detect patterns from often large data sets, closely related to knowledge discovery in databases and data science. In this investigation, we formulate models based on machine learning algorithms to extract relevant information predicting student retention at various levels, using higher education data and specifying the relevant variables involved in the modeling. Then, we utilize this information to help the process of knowledge discovery. We predict student retention at each of three levels during their first, second, and third years of study, obtaining models with an accuracy that exceeds 80% in all scenarios. These models allow us to adequately predict the level when dropout occurs. Among the machine learning algorithms used in this work are: decision trees, k-nearest neighbors, logistic regression, naive Bayes, random forest, and support vector machines, of which the random forest technique performs the best. We detect that secondary educational score and the community poverty index are important predictive variables, which have not been previously reported in educational studies of this type. The dropout assessment at various levels reported here is valid for higher education institutions around the world with similar conditions to the Chilean case, where dropout rates affect the efficiency of such institutions. Having the ability to predict dropout based on student’s data enables these institutions to take preventative measures, avoiding the dropouts. In the case study, balancing the majority and minority classes improves the performance of the algorithms.",data analytics; databases; data science; Friedman test; socioeconomic index; university dropout
Data Mining,Oppositional based Laplacian grey wolf optimization algorithm with SVM for data mining in intrusion detection system,Identifying intruders using data mining approach in recent trend provides better detection rate when compared with other classical systems. In this paper we introduced Oppositional based Laplacian grey wolf optimization algorithm for clustering the class of attacks based on the similarity and active learning of SVM classification using this optimization algorithm. The results of the proposed algorithm have been evaluated with standard metrics and compared with the recent algorithms to prove its significance. The results of the proposed algorithm show its significance when compared with the existing methodologies.,Intrusion detection system · Grey wolf optimisation  Support vector machine
Data Mining,Trends of global health literacy research (1995–2020): Analysis of mapping knowledge domains based on citation data mining ,"During uncertainties associated with the COVID-19 pandemic, effectively improving people’s health literacy is more important than ever. Drawing knowledge maps of health literacy research through data mining and visualized measurement technology helps systematically present the research status and development trends in global academic circles. Methods This paper uses CiteSpace to carry out a metric analysis of 9,492 health literacy papers included in Web of Science through mapping knowledge domains. First, based on the production theory of scientific knowledge and the data mining of citations, the main bodies (country, institution and author) that produce health literacy knowledge as well as their mutual cooperation (collaboration network) are both clarified. Additionally, based on the quantitative framework of cocitation analysis, this paper introduces the interdisciplinary features, development trends and hot topics of the field. Finally, by using burst detection technology in the literature, it further reveals the research frontiers of health literacy. Results The results of the BC measures of the global health literacy research collaboration network show that the United States, Australia and the United Kingdom are the major forces in the current international collaboration network on health literacy. There are still relatively very few transnational collaborations between Eastern and Western research institutions. Collaborations in public environmental occupational health, health care science services, nursing and health policy services have been active in the past five years. Research topics in health literacy research evolve over time, mental health has been the most active research field in recent years. Conclusions A systematic approach is needed to address the challenges of health literacy, and the network framework of cooperation on health literacy at regional, national and global levels should be strengthened to further promote the application of health literacy research. In the future, we anticipate that this research field will expand in two directions, namely, mental health literacy and eHealth literacy, both of which are closely linked to social development and issues. The results of this study provide references for future applied research in health literacy.",global health literacy knowledge domain data mining analysis
Data Mining,Sports decision-making model based on data mining and neural network,"The sports decision-making system is affected by many factors, and the sports decision-making system itself is a complex decision-making system, including multiple micro-systems. In order to construct a more scientific sports decision-making model, this paper builds a sports decision-making model based on data mining and neural network based on data mining technology and neural network algorithms. Moreover, based on the analysis of system theory, stakeholder theory and multi-objective decision-making theory, this paper provides a theoretical basis for the study of multi-objective decision-making problems in sports events. In addition, this paper discusses the starting point of decision-making and the scope of research from the basic concepts of sports decision-making and analyzes the multi-objective decision-making system of sports decision-making. At the same time, on this basis, this paper designs a multi-objective decision-making model for sports events, and finally conducts empirical research based on the designed model. Through empirical analysis and simulation research, it can be known that the combined model constructed in this paper performs well and has certain practical effects.",Data mining  Neural network  Machine learning  Sports decision-making
Data Mining,A Review of Data Mining Applications in Semiconductor Manufacturing,"For decades, industrial companies have been collecting and storing high amounts of data with the aim of better controlling and managing their processes. However, this vast amount of information and hidden knowledge implicit in all of this data could be utilized more efficiently. With the help of data mining techniques unknown relationships can be systematically discovered. The production of semiconductors is a highly complex process, which entails several subprocesses that employ a diverse array of equipment. The size of the semiconductors signifies a high number of units can be produced, which require huge amounts of data in order to be able to control and improve the semiconductor manufacturing process. Therefore, in this paper a structured review is made through a sample of 137 papers of the published articles in the scientific community regarding data mining applications in semiconductor manufacturing. A detailed bibliometric analysis is also made. All data mining applications are classified in function of the application area. The results are then analyzed and conclusions are drawn.",data mining; semiconductor manufacturing; quality control; yield improvement; fault detection; process control
Data Mining,CBO-IE: A Data Mining Approach for Healthcare IoT Dataset Using Chaotic Biogeography-Based Optimization and Information Entropy,"Data mining is mostly utilized for a huge variety of applications in several fields like education, medical, surveillance, and industries. )e clustering is an important method of data mining, in which data elements are divided into groups (clusters) to provide better quality data analysis. )e Biogeography-Based Optimization (BO) is the latest metaheuristic approach, which is applied to resolve several complex optimization problems. Here, a Chaotic Biogeography-Based Optimization approach using Information Entropy (CBO-IE) is implemented to perform clustering over healthcare IoT datasets. )e main objective of CBO-IE is to provide proficient and precise data point distribution in datasets by using Information Entropy concepts and to initialize the population by using chaos theory. Both Information Entropy and chaos theory are facilitated to improve the convergence speed of BO in global search area for selecting the cluster heads and cluster members more accurately. )e CBO-IE is implemented to a MATLAB 2021a tool over eight healthcare IoT datasets, and the results illustrate the superior performance of CBO-IE based on FMeasure, intracluster distance, running time complexity, purity index, statistical analysis, root mean square error, accuracy, and standard deviation as compared to previous techniques of clustering like K-Means, GA, PSO, ALO, and BO approaches.",IoT optimization optimisation information entropy data mining
Data Mining,A Comparative Analysis of Decision Trees Vis-`a-vis Other Computational Data Mining Techniques in Automotive Insurance Fraud Detection,"The development and application of computational data mining techniques in nancial fraud detection and business failure prediction has become a popular cross-disciplinary research area in recent times involv- ing nancial economists, forensic accountants and computational modellers. Some of the computational techniques popularly used in the context of - nancial fraud detection and business failure prediction can also be eectively applied in the detection of fraudulent insurance claims and therefore, can be of immense practical value to the insurance industry. We provide a compara- tive analysis of prediction performance of a battery of data mining techniques using real-life automotive insurance fraud data. While the data we have used in our paper is US-based, the computational techniques we have tested can be adapted and generally applied to detect similar insurance frauds in other countries as well where an organized automotive insurance industry exists.","ANNs, decision trees, fraud detection, logit model, survival analysis."
Data Mining,Big Data Analysis and Perturbation using Data Mining Algorithm,"The advancement and introduction of computing technologies has proven to be highly effective and has resulted in the production of large amount of data that is to be analyzed. However, there is much concern on the privacy protection of the gathered data which suffers from the possibility of being exploited or exposed to the public. Hence, there are many methods of preserving this information they are not completely scalable or efficient and also have issues with privacy or data utility. Hence this proposed work provides a solution for such issues with an effective perturbation algorithm that uses big data by means of optimal geometric transformation. The proposed work has been examined and tested for accuracy, attack resistance, scalability and efficiency with the help of 5 classification algorithms and 9 datasets. Experimental analysis indicates that the proposed work is more successful in terms of attack resistance, scalability, execution speed and accuracy when compared with other algorithms that are used for privacy preservation. ","Big data, data perturbation, big data privacy, privacy-preservation data mining, information privacy"
Human Computer Interaction,The Talent Training Mode of International Service Design Using a Human-Computer Interaction Intelligent Service Robot From the Perspective of Cognitive Psychology,"To effectively improve the efficiency of international service design talent training and make it more in line with society's needs, we analyze the current status of international service design talent training and its professional training focus. Based on the above problems, from the perspective of cognitive psychology, artificial intelligence and human-computer interaction (HCI) technology are used to construct the international service design talent training mode of the HCI intelligent service robot. This mode can be used to solve the existing teaching problems by using novel means to ensure the quality of teaching. Finally, through the actual analysis of teaching cases, the effectiveness of the proposed talent training mode is verified. The HCI system is based on knowledge of cognitive psychology. According to the characteristics and functions of an educational robot, the robot is combined with traditional teaching activities, and the robot-assisted talent training mode is designed. Robot-assisted talent training is a feasible training method that can improve the efficiency of talent training. Students have confidence in their learning skills before the course, and the confidence is further strengthened after the end of the course. After the course, the students have a stronger sense of cooperation. This study can provide theoretical ideas for the research of international service talent training mode.",artificial intelligence; cognitive psychology; robot; talent training; talent training mode
Human Computer Interaction,Embracing Four Tensions in Human-Computer Interaction Research with Marginalized People,"Human-computer interaction has a long history of working with marginalized people. We sought to understand how HCI researchers navigate work that engages with marginalized people and considerations researchers might work through to expand benefits and mitigate potential harms. In total, 24 HCI researchers, located primarily in the United States, participated in an interview, survey, or both. Through a reflexive thematic analysis, we identified four tensions—exploitation, membership, disclosure, and allyship. We explore the complexity involved in each, demonstrating that an equitable endpoint may not be possible, but this work is still worth pursuing when researchers make certain considerations. We emphasize that researchers who work with marginalized people should account for each tension in their research approaches to move forward. Finally, we propose an allyship-oriented approach to research that draws inspiration from discourse occurring in tangential fields and activist spaces and pushes the field into a new paradigm of research with marginalized people.","Marginalized people, exploitation, membership, disclosure, allyship, tensions HCI "
Human Computer Interaction,Hand Gestures Recognition Using Radar Sensors for Human-Computer-Interaction: A Review,": Human–Computer Interfaces (HCI) deals with the study of interface between humans and computers. The use of radar and other RF sensors to develop HCI based on Hand Gesture Recognition (HGR) has gained increasing attention over the past decade. Today, devices have built-in radars for recognizing and categorizing hand movements. In this article, we present the first ever review related to HGR using radar sensors. We review the available techniques for multi-domain hand gestures data representation for different signal processing and deep-learning-based HGR algorithms. We classify the radars used for HGR as pulsed and continuous-wave radars, and both the hardware and the algorithmic details of each category is presented in detail. Quantitative and qualitative analysis of ongoing trends related to radar-based HCI, and available radar hardware and algorithms is also presented. At the end, developed devices and applications based on gesturerecognition through radar are discussed. Limitations, future aspects and research directions related to this field are also discussed.",hand-gesture recognition; pulsed radar; continuous-wave radars; human–computer interfaces; deep-learning for radar signals
Human Computer Interaction,Braving Citational Justice in Human-Computer Interaction,"Citations are central to the production and sharing of knowledge, and how, why, and where citations are used has been an intense subject of study across disciplines. We discuss citational practices and the politics of knowledge production within the field of Human-Computer Interaction (HCI), drawing on parallels from related fields, and reflecting on our own experiences of being cited and not cited, citing and not citing. We also present recommendations for making concrete changes across the individual and the structural in HCI, related to how citations are viewed, and how the field might advance in solidarity towards greater citational justice.",Citational justice; knowledge production HCI Human computer interaction
Human Computer Interaction,Mapping Human–Computer Interaction Research Themes and Trends from Its Existence to Today: A Topic Modeling-Based Review of past 60 Years,"As it covers a wide spectrum, the research literature of human-computer interaction (HCI) studies has a rich and multi-disciplinary content where there are limited studies demonstrating the big picture of the field. Such an analysis provides researchers with a better understanding of the field, revealing current issues, challenges, and potential research gaps. This study aims to explore the research trends in the developmental stages of the HCI studies over the past 60 years. Automated text mining with probabilistic topic modeling has been used to analyze 41,720 journal articles that are indexed by the SCOPUS database between 1957 and 2018. The results of this study reveal 21 major topics mapping the research landscape of HCI. By extending the discovered topics beyond a snapshot, the topics were analyzed considering their developmental stages, volume, and accelerations to provide a panoramic view that shows the increase and decrease of trends over time. In this context, the transition of HCI studies from machine-oriented systems to human-oriented systems indicates its future direction toward context-aware adaptive systems.",HCI adaptive systems HCI research themes topic modeling 
Human Computer Interaction,User Representations in Human-Computer Interaction,"Cursors, avatars, virtual hands or tools, and other rendered graphical objects, enable users to interact with computers such as PCs, game consoles or virtual reality systems. We analyze the role of these various objects from a user perspective under the unifying concept of “User Representations”. These representations are virtual objects that artificially extend the users’ physical bodies, enabling them to manipulate the virtual environment by performing motor actions that are continuously mapped to their User Representations. In this paper, we identify a set of concepts that are relevant for different User Representations, and provide a multidisciplinary review of the multisensory and cognitive factors underlying the control and subjective experience of User Representations. These concepts include visual appearance, multimodal feedback, sense of agency, input methods, peripersonal space, visual perspective, and body ownership. We further suggest a research agenda for these concepts, which can lead the human-computer interaction community towards a wider perspective of how users perceive and interact through their User Representations.",User representations multimodal feedback peripersonal space visual perspective sense of agency body ownership
Human Computer Interaction,Anisotropic angle distribution learning for head pose estimation and attention understanding in human-computer interaction,"Head pose estimation is an important way to understand human attention in the human-computer interaction. In this paper, we propose a novel anisotropic angle distribution learning (AADL) network for head pose estimation task. Firstly, two key findings are revealed as following: 1) Head pose image variations are different at the yaw and pitch directions with the same pose angle increasing on a fixed central pose; 2) With the fixed angle interval increasing, the image variations increase firstly and then decrease in yaw angle direction. Then, the maximum a posterior technology is employed to construct the head pose estimation network, which includes three parts, such as convolutional layer, covariance pooling layer and output layer. In the output layer, the labels are constructed as the anisotropic angle distributions on the basis of two key findings. And the anisotropic angle distributions are fitted by the 2D Gaussian-like distributions (groundtruth labels). Furthermore, the Kullback-Leibler divergence is selected to measure the predication label and the groundtruth one. The features of head pose images are perceived at the AADL-based convolutional neural network in an end-to-end manner. Experimental results demonstrate that the developed AADL-based labels have several advantages, such as robustness for head pose image missing, insensitivity for the motion blur. Moreover, the proposed method has achieved good performance compared to several state-of-the-art methods on the Pointing’04 and CAS_PEAL_R1 databases.",Head pose estimation Anisotropic angle distribution Convolutional neural network Regularization Learning behavior analysis Human-computer interaction
Human Computer Interaction,Deep learning-based facial emotion recognition for human–computer interaction applications,"One of the most significant fields in the man–machine interface is emotion recognition using facial expressions. Some of the challenges in the emotion recognition area are facial accessories, non-uniform illuminations, pose variations, etc. Emotion detection using conventional approaches having the drawback of mutual optimization of feature extraction and classification. To overcome this problem, researchers are showing more attention toward deep learning techniques. Nowadays, deep-learning approaches are playing a major role in classification tasks. This paper deals with emotion recognition by using transfer learning approaches. In this work pre-trained networks of Resnet50, vgg19, Inception V3, and Mobile Net are used. The fully connected layers of the pre-trained ConvNets are eliminated, and we add our fully connected layers that are suitable for the number of instructions in our task. Finally, the newly added layers are only trainable to update the weights. The experiment was conducted by using the CK + database and achieved an average accuracy of 96% for emotion detection problems.",Human–computer interaction  Transfer learning  Resnet50  VGG 19  Inception V3  MobileNet
Human Computer Interaction,A Review of Human–Computer Interaction and Virtual Reality Research Fields in Cognitive InfoCommunications,"Cognitive infocommunications (CogInfoCom) is a young and evolving discipline that is at the crossroads of information and communication technology (ICT) and cognitive sciences with many promising results. The goal of the field is to provide insights into how human cognitive capabilities can be merged and extended with the cognitive capabilities of the digital devices surrounding us, with the goal of enabling more seamless interactions between humans and artificially cognitive agents. Results in the field have already led to the appearance of numerous CogInfoCom-based technological innovations. For example, the field has led to a better understanding of how humans can learn more effectively, and the development of new kinds of learning environment have followed accordingly. The goal of this paper is to summarize some of the most recent results in CogInfoCom and to introduce important research trends, developments and innovations that play a key role in understanding and supporting the merging of cognitive processes with ICT.",cognitive infocommunications; CogInfoCom; HCI; VR
Human Computer Interaction,Federated Learning Meets Human Emotions: A Decentralized Framework for Human–Computer Interaction for IoT Applications,"As stated by Spock, “change is the essential process of all existence,” which is reflected in everyday applications in our daily lives. We, as humans, just need to find a way to make the best use of the current technological advances. The pandemic has managed to exploit our deepest vulnerabilities and insecurities. We need to cope with a lot of things, just to be comfortable in the new normal. Hence, we can rely on technology, the greatest asset developed by humans. In this article, we discuss how we can enhance the work environment in offices post-pandemic. We combine federated learning with emotion analysis to create a state-of-the-art, simple, secure, and efficient emotion monitoring system. We combine facial expression and speech signals to find out macroexpressions and create an emotion index that is monitored to find the mental health of the user. Federated learning enables users to locally train the model without compromising his/her privacy. In place of sending data to the centralized server, the proposed scheme sends only model weights that are combined at the server to make a better global model, which is further pushed back to the users. This model is then trained interorganizational as it does not violate the privacy or data sharing to achieve optimal results. The data collected from users are monitored to analyze the mental health and presented with counseling solutions during low times. Technology is a panacea that has enabled us to survive in this pandemic, and by using our solution to improve work culture and the environment in post-pandemic times.","Computer vision, federated learning, machine learning, sentiment analysis"
Human Computer Interaction,Human–computer interaction-based Decision Support System with Applications in Data Mining,"Human–computer interaction (HCI) plays a vital role in modern intelligent systems, such as brain–machine integration, human action recognition, telemedicine, and somatosensory game. A decision support system is a combination of the information system and decision-making technology. Visual human–computer interaction decision-making is a key technique in the decision support system. This paper proposes a new visual decision-making system applicable for industrial applications, i.e. data mining topics. To assist the performance of the proposed visual decision-making system, it is designed for data mining technique applications. Furthermore, the architecture of the decision support system is analyzed based on practical data mining case study. The comprehensive experiment shows that the proposed method is effective and robust in comparison to other methods.",Human–computer interactionData miningDecision support systemDecision-makingIntelligent systems
Human Computer Interaction,Smart city as a smart service system: Human-computer interaction and smart city surveillance systems,"Smart city services, smart applications and smart devices form an ecosystem of tools and artifacts that challenge, and times even disrupt, conventions, norms, and rites of behavior, thus prompting diverse behavioral changes at the level of the individual, the group, and the society at large. In this view, smart city may be viewed as a – one of its kind – laboratory to query the complex human-computer relationship from a multi-dimensional perspective. By adopting this perspective, this paper queries the existing smart city surveillance systems to identify their key limitations and sources of frequently justified controversies. It is argued that to bypass these – first – the value of mesh-technology should be explored. It is also argued that – second – it is necessary not only to bring citizens back in the discussion on smart city, but also to highlight the mechanisms by means of which they might be involved in the co-design of smart city solutions and in urban decision-making. To bridge these two imperatives, smart city is conceptualized as a smart service system and, consequently, a wireless integrated mesh-technology enhanced (WIMTE) smart city surveillance system is elaborated.",Smart citySmart service systemsSurveillance systemsHuman-computer interactionMesh technologyCitizen behavior
Human Computer Interaction,A Systematic Review of Human–Computer Interaction and Explainable Artificial Intelligence in Healthcare With Artificial Intelligence Techniques,"Artificial intelligence (AI) is one of the emerging technologies. In recent decades, artificial intelligence (AI) has gained widespread acceptance in a variety of fields, including virtual support, healthcare, and security. Human-Computer Interaction (HCI) is a field that has been combining AI and human-computer engagement over the past several years in order to create an interactive intelligent system for user interaction. AI, in conjunction with HCI, is being used in a variety of fields by employing various algorithms and employing HCI to provide transparency to the user, allowing them to trust the machine. The comprehensive examination of both the areas of AI and HCI, as well as their subfields, has been explored in this work. The main goal of this article was to discover a point of intersection between the two fields. The understanding of Explainable Artificial Intelligence (XAI), which is a linking point of HCI and XAI, was gained through a literature review conducted in this research. The literature survey encompassed themes identified in the literature (such as XAI and its areas, major XAI aims, and XAI problems and challenges). The study’s other major focus was on the use of AI, HCI, and XAI in healthcare. The poll also addressed the shortcomings in XAI in healthcare, as well as the field’s future potential. As a result, the literature indicates that XAI in healthcare is still a novel subject that has to be explored more in the future.","Artificial intelligence, deep learning, explainable artificial intelligence, healthcare, human-computer interaction, human-centered design, machine learning, usability, user-centered design."
Human Computer Interaction,Embodied Human Computer Interaction,"In this paper, we argue that embodiment can play an important role in the design and modeling of systems developed for Human Computer Interaction. To this end, we describe a simulation platform for building Embodied Human Computer Interactions (EHCI). This system, VoxWorld, enables multimodal dialogue systems that communicate through language, gesture, action, facial expressions, and gaze tracking, in the context of task-oriented interactions. A multimodal simulation is an embodied 3D virtual realization of both the situational environment and the co-situated agents, as well as the most salient content denoted by communicative acts in a discourse. It is built on the modeling language VoxML (Pustejovsky and Krishnaswamy in VoxML: a visualization modeling language, proceedings of LREC, 2016), which encodes objects with rich semantic typing and action affordances, and actions themselves as multimodal programs, enabling contextually salient inferences and decisions in the environment. VoxWorld enables an embodied HCI by situating both human and artificial agents within the same virtual simulation environment, where they share perceptual and epistemic common ground. We discuss the formal and computational underpinnings of embodiment and common ground, how they interact and specify parameters of the interaction between humans and artificial agents, and demonstrate behaviors and types of interactions on different classes of artificial agents.",Multimodal embodiment · Simulation · Artifcial agent · Situated grounding
Human Computer Interaction,Data Comics for Reporting Controlled User Studies in Human-Computer Interaction,"Inspired by data comics, this paper introduces a novel format for reporting controlled studies in the domain of humancomputer interaction (HCI). While many studies in HCI follow similar steps in explaining hypotheses, laying out a study design, and reporting results, many of these decisions are buried in blocks of dense scientific text. We propose leveraging data comics as study reports to provide an open and glanceable view of studies by tightly integrating text and images, illustrating design decisions and key insights visually, resulting in visual narratives that can be compelling to non-scientists and researchers alike. Use cases of data comics study reports range from illustrations for non-scientific audiences to graphical abstracts, study summaries, technical talks, textbooks, teaching, blogs, supplementary submission material, and inclusion in scientific articles. This paper provides examples of data comics study reports alongside a graphical repertoire of examples, embedded in a framework of guidelines for creating comics reports which was iterated upon and evaluated through a series of collaborative design sessions.","Statistical communication, comics, scientific reports"
Human Computer Interaction,Knitted Ti3C2Tx MXene based fiber strain sensor for human-computer interaction.,"Fiber-based stretchable electronics with feasibility of weaving into textiles and advantages of light-weight, long-term stability, conformability and easy integration are highly desirable for wearable electronics to realize personalized medicine, artificial intelligence and human health monitoring. Herein, a fiber strain sensor is developed based on the Ti3C2Tx MXene wrapped by poly(vinylidenefluoride-co-trifluoroethylene) (P(VDF-TrFE)) polymer nanofibers prepared via electrostatic spinning. Owing to the good conductivity of Ti3C2Tx and unique 3D reticular structure with wave shape, the resistance of Ti3C2Tx@P(VDF-TrFE) polymer nanofibers changes under external force, thus providing remarkable strain inducted sensing performance. As-fabricated sensor exhibits high gauge factor (GF) of 108.8 in range of 45-66% strain, rapid response of 19 ms, and outstanding durability over 1600 stretching/releasing cycles. The strain sensor is able to monitor vigorous human motions (finger or wrist bending) and subtle physiological signals (blinking, pulse or voice recognition) in real-time. Moreover, a data glove is designed to connect different gestures and expressions to form an intelligent gesture-expression control system, further confirming the practicability of our Ti3C2Tx@P(VDF-TrFE) strain sensors in multifunctional wearable electronic devices.",Data glove; Fiber electronics; Human-computer interaction; MXene; Strain sensor.
Human Computer Interaction,A bibliometric study of human–computer interaction research activity in the Nordic-Baltic Eight countries,"Human–computer interaction (HCI) has become an important area for designers and developers worldwide, and research activities set in national cultural contexts addressing local challenges are often needed in industry and academia. This study explored HCI research in the Nordic-Baltic countries using bibliometric methods. The results show that the activity varies greatly across the region with activities dominated by Finland, Sweden, and Denmark, even when adjusting for diferences in population size and GDP. Research output variations were larger for the top-tier conferences compared to entry-tier conferences and journals. Locally hosted conferences were associated with local increases in research activity. HCI research longevity appears to be an indicator of research maturity and quantity. HCI researchers typically collaborated either with colleagues within the same institution or with researchers from countries outside the Nordic-Baltic region such as US and the UK. There was less collaboration between national and Nordic-Baltic partners. Collaboration appeared especially prevalent for top-tier conference papers. Top-tier conference papers were also more frequently cited than regional-tier and entry-tier conferences, yet journal articles were cited the most. One implication of this study is that the HCI research activity gaps across the Nordic-Baltic countries should be narrowed by increasing the activity in countries with low research outputs. To achieve this, frst-time authors could receive guidance through collaborations with experienced authors in the same institution or other labs around the world. More conferences could also be hosted locally. Furthermore, journals may be more efective than conferences if the goal is to accumulate citations.",HCI research · Bibliometrics · Scientometrics · Research output · Publications · Collaboration  Nordic-Baltic Eight countries
Human Computer Interaction,Evaluation in Human-Computer Interaction Beyond Lab Studies,"Many research contributions in human-computer interaction are based on user studies in the lab. However, lab studies are not always possible, and they may come with signifcant challenges and limitations. In this course, we take a broader look at diferent approaches to doing research. We present a set of evaluation methods and research contributions that do not rely on user studies in labs. The discussion focuses on research approaches, data collection methods, and tools that can be conducted without direct interaction between the researchers and the participants.","Evaluation Method, Remote Studies, Datasets"
Human Computer Interaction,Patient Emotion Recognition in Human Computer Interaction System Based on Machine Learning Method and Interactive Design Theory,"There are more and more human computer interaction systems (HCIS) in the medical field. Improving the service quality of HCIS and making them more intelligent is an inevitable trend in the future. Emotion recognition is of great significance for patients using HCIS. Some excellent HCIS not only satisfies the needs of patients, but also judges the emotional state of patients based on the results of emotional recognition, thereby providing more intimate medical services. Therefore, emotion recognition is crucial for HCIS. To effectively optimize the correct rate of emotion recognition, a novel emotion recognition framework based on machine learning is proposed. The core of the framework is to select the optimal classifier for different emotional data, and fuse the classification results of each classifier to get the global classification result. Experiments demonstrate that the proposed framework not only improves the accuracy of emotion recognition, but also improves the stability and reliability of the recognition results. The emotion recognition function based on the framework is applied to the HCIS design, so that the HCIS of the medical institution can better serve the patient during use, keep the patient happy, and improve the patient's happiness index and rehabilitation rate.", EMOTION RECOGNITION FRAMEWORK; HCIS; MACHINE LEARNING; PATIENTS
Human Computer Interaction,Simulation of English classroom effectiveness based on human-computer interaction and facial identification,"A variety of factors affect English classroom teaching, which prevents teachers from effectively grasping students’ learning status and learning situation. In particular, classroom management is more difficult during online teaching. In order to improve the effectiveness of English classroom teaching, based on the human-computer interaction algorithm and facial identification algorithm, this paper effectively recognizes the human-computer interaction process and classroom learning status of students in online teaching, and eliminates the image background according to the actual teaching needs. Moreover, by extracting and fusing the time sequence information and spatial information of the motion in the video, a spatiotemporal feature image capable of expressing a dynamic typical feature is obtained. In addition, this paper uses system algorithms to judge the status and feed back the identification results to the teacher’s teaching terminal equipment, which is convenient for timely teaching adjustment. Finally, this paper analyzes the effectiveness of the algorithm through simulation experiments. The research results show that the algorithm constructed in this paper has good performance.","Human-computer interaction, facial identification, English classroom, teaching simulation"
Human Computer Interaction,Research Trends of Human–Computer Interaction Studies in Construction Hazard Recognition: A Bibliometric Review,"Human–computer interaction, an interdisciplinary discipline, has become a frontier research topic in recent years. In the fourth industrial revolution, human–computer interaction has been increasingly applied to construction safety management, which has significantly promoted the progress of hazard recognition in the construction industry. However, limited scholars have yet systematically reviewed the development of human–computer interaction in construction hazard recognition. In this study, we analyzed 274 related papers published in ACM Digital Library, Web of Science, Google Scholar, and Scopus between 2000 and 2021 using bibliometric methods, systematically identified the research progress, key topics, and future research directions in this field, and proposed a research framework for human–computer interaction in construction hazard recognition (CHR-HCI). The results showed that, in the past 20 years, the application of human–computer interaction not only made significant contributions to the development of hazard recognition, but also generated a series of new research subjects, such as multimodal physiological data analysis in hazard recognition experiments, development of intuitive devices and sensors, and the human–computer interaction safety management platform based on big data. Future research modules include computer vision, computer simulation, virtual reality, and ergonomics. In this study, we drew a theoretical map reflecting the existing research results and the relationship between them, and provided suggestions for the future development of human–computer interaction in the field of hazard recognition from a practical perspective.",human-computer interaction; construction; hazard recognition; bibliometric review
Human Computer Interaction,Design and Implementation of Human-Computer Interaction Systems Based on Transfer Support Vector Machine and EEG Signal for Depression Patients’ Emotion Recognition,"At present, the demand for intelligentization of human-computer interaction systems (HCIS) has become increasingly prominent. Being able to recognize the emotions of users of interactive systems is a distinguishing feature of intelligent interactive systems. The intelligent HCIS can analyze the emotional changes of patients with depression, complete the interaction with the patients in a more appropriate manner, and the recognition results can assist family members or medical personnel to make response measures based on the patient’s emotional changes. Based on this background, this paper proposes a sentiment recognition method based on transfer support vector machines (TSVM) and EEG signals. The ER (ER) results based on this method are applied to HCIS. Such a HCIS is mainly used for the interaction of patients with depression. When a new field related to a certain field appears, if the new field data is relabeled, the sample is expensive, and it is very wasteful to discard all the old field data. The main innovation of this research is that the introduced classification model is TSVM. TSVM is a transfer learning strategy based on SVM. Transfer learning aims to solve related but different target domain problems by using a large amount of labeled source domain data. Therefore, the transfer support vector machine based on the transfer mechanism can use the small labeled data of the target domain and a large amount of old data in the related domain to build a high-quality classification model for the target domain, which can effectively improve the accuracy of classification. Comparing the classification results with other classification models, it can be concluded that TSVM can effectively improve the accuracy of ER in patients with depression. The HCIS based on the classification model has higher accuracy and better stability.", EEG Signals; ER; HCIS; Support Vector Machine; Transfer Learning
Human Computer Interaction,A Review of HumanComputer Interaction Design Approaches towards Information Systems Development,"Nowadays modern information systems (emerging technologies) are increasingly becoming an integral part of our daily lives and has begun to pose a serious challenge for human-computer interaction (HCI) professionals, as emerging technologies in the area of mobile and cloud computing, and internet of things (IoT), are calling for more devotion from HCI experts in terms of systems interface design. As the number of mobile platforms users, nowadays comprises of children’s, elderly people, and people with disabilities or disorders, all demanding for an effective user interface that can meet their diverse needs, even on the move, at anytime and anywhere. This paper, review current articles (43) related to HCI interface design approaches to modern information systems design with the aim of identifying and determining the effectiveness of these methods. The study found that the current HCI design approaches were based on desktop paradigm which falls short of providing location-based services to mobile platforms users. The study also discovered that almost all the current interface design standard used by HCI experts for the design of user’s interface were not effective & supportive of emerging technologies due to the flexibility nature of these technologies. Based on the review findings, the study suggested the combination of Human-centred design with agile methodologies for interface design, and call on future works to use qualitative or quantitative approach to further investigate HCI methods of interface design with much emphasis on cloud-based technologies and other organizational information systems.",HCI design approaches; Information systems Development; Emerging-technologies; Mobile platforms; Agile methodology; User interface
Human Computer Interaction,The College Students’ Oral English Education Strategy Using Human-Computer Interaction Simulation System From the Perspective of Educational Psychology,"The role of the human-computer interaction (HCI) system in college students' oral English learning is discussed to analyze the current situation of college students' oral English based on the HCI simulation system. The purpose is to study the oral education of college students. First, the theories of educational psychology, the HCI system, and the current situation of college students' oral English learning are elaborated. Meanwhile, in oral English teaching, teachers use support vector machines and multimodal fusion intention perception methods in set theory to realize the interactive teaching between students and machines; then, the HCI simulation of oral English is explained. The current situation of college students' oral English learning is analyzed by a questionnaire from the perspective of educational psychology. Finally, the HCI system in college students' oral English learning is explored based on the learning level detection. The results show that 12% of college students are unqualified in oral English; 25% of them think their oral English level is medium; most of college students' English learning anxiety is related to English progress anxiety; 18% of the students believe that they will study oral English for life; 32% of the students think that they have more opportunities to learn English at ordinary times; and most of the students learn English through English movies and songs outside of class. What attracts college students to learn oral English through the HCI system is that learning is not limited by time and space. Most students believe that their English level is good and hope that learning anxiety can be reduced through HCI systems. The strategies of college students' oral English education with an HCI simulation system are evaluated based on the perspective of educational psychology, providing a research basis for oral English education in other regions and even the whole country to facilitate the better development of oral English education.",educational psychology; educational strategy; human–computer interaction; oral English education; simulation.
Human Computer Interaction,Content based video retrieval system based on multimodal feature grouping by KFCM clustering algorithm to promote human–computer interaction,"Content Based Video Retrieval (CBVR) is so popular these days, because of the increased utilization of video based analytical systems. Video based analytics is quite efective than image analysis, as a series of actions are captured by the video. This ends up with better decision making ability. The CBVR systems play an important role in boosting the human–computer interaction. This paper presents a multimodal CBVR that takes both the visual and audio information into account for retrieving relevant videos to the user. Two modules are employed by this work to deal with video and audio data. The video data is processed to detect the signifcant frame from shots and is achieved by Lion Optimization Algorithm (LOA). The features are extracted from the visual data and with respect to the audio data, MHEC and LPCC features are extracted. The extracted features are clustered by Kernelized Fuzzy C Mean (KFCM) algorithm. Finally, the feature database is formed and is utilized in the query matching process during the testing phase. The performance of the proposed work is tested in terms of precision, recall, F-measure and time consumption rates. The proposed CBVR system proves better performance than the existing approaches and is evident through attained results.",Human–computer interaction · Content based video retrieval (CBVR) · Video analysis · Feature extraction · Signifcant frame detection
Software Engineering,Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure,"Datasets that power machine learning are often used, shared, and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks, system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data, and accountability for decisions made when developing it. In this paper, we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decisionmaking, as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation, a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes.","datasets, requirements engineering, machine learning , software engineering"
Software Engineering,App Store Effects on Software Engineering Practices,"In this paper, we study the app store as a phenomenon from the developers’ perspective to investigate the extent to which app stores affect software engineering tasks. Through developer interviews and questionnaires, we uncover findings that highlight and quantify the effects of three high-level app store themes: bridging the gap between developers and users, increasing market transparency and affecting mobile release management. Our findings have implications for testing, requirements engineering and mining software repositories research fields. These findings can help guide future research in supporting mobile app developers through a deeper understanding of the app store-developer interaction.","Empirical software engineering, mobile app development, app store analysis"
Software Engineering,Bayesian Data Analysis in Empirical Software Engineering Research,"—Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics have traditionally dominated empirical data analysis, and certainly remain prevalent in empirical software engineering. This situation is unfortunate because frequentist statistics suffer from a number of shortcomings—such as lack of flexibility and results that are unintuitive and hard to interpret—that curtail their effectiveness when dealing with the heterogeneous data that is increasingly available for empirical analysis of software engineering practice. In this paper, we pinpoint these shortcomings, and present Bayesian data analysis techniques that provide tangible benefits—as they can provide clearer results that are simultaneously robust and nuanced. After a short, high-level introduction to the basic tools of Bayesian statistics, we present the reanalysis of two empirical studies on the effectiveness of automatically generated tests and the performance of programming languages. By contrasting the original frequentist analyses with our new Bayesian analyses, we demonstrate the concrete advantages of the latter. To conclude we advocate a more prominent role for Bayesian statistical techniques in empirical software engineering research and practice.","Bayesian data analysis, statistical analysis, statistical hypothesis testing, empirical software engineering"
Software Engineering,"A Progression Model of Software Engineering Goals, Challenges, and Practices in Start-Ups","Context: Software start-ups are emerging as suppliers of innovation and software-intensive products. However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups. As a result, there is insufficient support for software engineering in the start-up context. Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups. Such data allows researchers to understand better how goals and challenges are related to practices. This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges. Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice. Method: We use a case survey method to gather firsthand, in-depth experiences from a large sample of software start-ups. We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis. Results: We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups. We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity). Thus, creating the progression model guiding software engineering efforts in start-ups. Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies. However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors.","Software start-up, software engineering practices, progression model"
Software Engineering,Toward a Quantum Software Engineering,"Nowadays, we are at the dawn of a new age, the quantum era. Quantum computing is no longer a dream; it is a reality that needs to be adopted. But this new technology is taking its first steps, so we still do not have models, standards, or methods to help us in the creation of new systems and the migration of current ones. Given the current state of quantum computing, we need to go back to the path software engineering took in the last century to achieve the new golden age for quantum software engineering.",quantum computing software engineering golden age technology 
Software Engineering,Exploring the intersection between software industry and Software Engineering education - A systematic mapping of Software Engineering Trends,"Context: Software has become ubiquitous in every corner of modern societies. During the last five decades, software engineering has also changed significantly to advance the development of various types and scales of software products. In this context, Software Engineering Education plays an important role in keeping students updated with software technologies, processes, and practices that are popular in industries. Objective: We investigate from literature the extent Software Engineering Education addresses major Software Engineering Trends in the academic setting. Method: We conducted a systematic mapping study about teaching major Software Engineering Trends in project courses. We classified 126 papers based on their investigated Software Engineering Trends, specifically Software Engineering processes and practices, teaching approaches, and the evolution of Software Engineering Trends over time. Results: We reveal that Agile Software Development is the major trend. The other Trends, i.e., Software Implementation, Usability and Value, Global Software Engineering, and Lean Software Startup, are relatively small in the academic setting, but continuously growing in the last five years. System of Systems is the least investigated among all Trends. Conclusions: The study points out the possible gaps between Software Industry and Education, which implies actionable insights for researchers, educators, and practitioners.",Software industry Software Engineering Education Software Engineering Trends Industry education intersection Systematic mapping study
Software Engineering,A Software Engineering Perspective on Engineering Machine Learning Systems: State of the Art and Challenges,"Context: Advancements in machine learning (ML) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to ML systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems. Objective: The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering (SE) research for engineering ML systems. Method: I performed a systematic literature review (SLR). I systematically selected a pool of 141 studies from SE venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies. Results: The non-deterministic nature of ML systems complicates all SE aspects of engineering ML systems. Despite increasing interest from 2018 onwards, the results reveal that none of the SE aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing ML systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of ML systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions. Conclusion: The results may benefit (1) practitioners in foreseeing the challenges of ML systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating SE courses to cover ML systems engineering.",Software engineering; software development; software process; machine learning; deep learning; systematic literature review
Software Engineering,A Case for Human Values in Software Engineering,"This article argues that human values—such as responsibility, transparency, creativity, and equality—are heavily underrepresented in software engineering methods. Using experience with projects involving notfor-prot organizations, we explored how human values can be integrated into existing participatory agile practices.",transparency creativity software engineering 
Software Engineering,SEthesaurus: WordNet in Software Engineering,"Informal discussions on social platforms (e.g., Stack Overflow, CodeProject) have accumulated a large body of programming knowledge in the form of natural language text. Natural language process (NLP) techniques can be utilized to harvest this knowledge base for software engineering tasks. However, consistent vocabulary for a concept is essential to make an effective use of these NLP techniques. Unfortunately, the same concepts are often intentionally or accidentally mentioned in many different morphological forms (such as abbreviations, synonyms and misspellings) in informal discussions. Existing techniques to deal with such morphological forms are either designed for general English or mainly resort to domain-specific lexical rules. A thesaurus, which contains software-specific terms and commonly-used morphological forms, is desirable to perform normalization for software engineering text. However, constructing this thesaurus in a manual way is a challenge task. In this paper, we propose an automatic unsupervised approach to build such a thesaurus. In particular, we first identify software-specific terms by utilizing a software-specific corpus (e.g., Stack Overflow) and a general corpus (e.g., Wikipedia). Then we infer morphological forms of software-specific terms by combining distributed word semantics, domain-specific lexical rules and transformations. Finally, we perform graph analysis on morphological relations. We evaluate the coverage and accuracy of our constructed thesaurus against community-cumulated lists of software-specific terms, abbreviations and synonyms. We also manually examine the correctness of the identified abbreviations and synonyms in our thesaurus. We demonstrate the usefulness of our constructed thesaurus by developing three applications and also verify the generality of our approach in constructing thesauruses from data sources in other domains.","Software-specific thesaurus, natural language processing, morphological form, word embedding"
Software Engineering,An assessment of student satisfaction with e-learning: An empirical study with computer and software engineering undergraduate students in Turkey under pandemic conditions,"As COVID-19 reached Turkey in March 2020, all universities switched to e-learning in a very short period. Computer and software engineering (CE/SE) undergraduate students studying at university campuses have switched to e-learning. This paper seeks to understand the e-learning experience of CE/SE undergraduate students. A questionnaire was created and applied to CE/SE undergraduate students in Turkish universities. The data were analyzed using quantitative and qualitative techniques. The questionnaire received 290 usable responses. The highlights from the findings include: the participants (1) used video recordings intensively for e-learning and found them useful; (2) found face-to-face lectures more beneficial compared to digital live lectures; (3) used external online resources to improve their learning performance in courses; (4) thought that the materials and methods utilized for assessment should be adapted to e-learning for a better and fair evaluation; (5) perceived significantly less instructor support and classmate interaction and collaboration in e-learning compared to on-campus education settings; (6) rated their perceived satisfaction from e-learning as 2.85, slightly under the mid-level of the 5-point Likert scale; (7) perceived instructor support, student interaction and collaboration, and student autonomy as noteworthy factors in high-quality e-learning.",COVID-19; Computer engineering education; E-learning; Empirical study; On-campus education; Pandemic; Software engineering education.
Software Engineering,A Survey on Deep Learning for Software Engineering,"In 2006, Geoffrey Hinton proposed the concept of training “Deep Neural Networks (DNNs)” and an improved model training method to break the bottleneck of neural network development. More recently, the introduction of AlphaGo in 2016 demonstrated the powerful learning ability of deep learning and its enormous potential. Deep learning has been increasingly used to develop state-of-the-art software engineering (SE) research tools due to its ability to boost performance for various SE tasks. There are many factors, e.g., deep learning model selection, internal structure differences, and model optimization techniques, that may have an impact on the performance of DNNs applied in SE. Few works to date focus on summarizing, classifying, and analyzing the application of deep learning techniques in SE. To fill this gap, we performed a survey to analyze the relevant studies published since 2006. We first provide an example to illustrate how deep learning techniques are used in SE. We then conduct a background analysis (BA) of primary studies and present four research questions to describe the trend of DNNs used in SE (BA), summarize and classify different deep learning techniques (RQ1), and analyze the data processing including data collection, data classification, data pre-processing, and data representation (RQ2). In RQ3, we depicted a range of key research topics using DNNs and investigated the relationships between DL-based model adoption and multiple factors (i.e., DL architectures, task types, problem types, and data types). We also summarized commonly used datasets for different SE tasks. In RQ4, we summarized the widely used optimization algorithms and provided important evaluation metrics for different problem types, including regression, classification, recommendation, and generation. Based on our findings, we present a set of current challenges remaining to be investigated and outline a proposed research road map highlighting key opportunities for future work.","Deep learning, neural network, machine learning, software engineering, survey"
Software Engineering,Initiatives and Challenges of Using Gamification in Software Engineering: A Systematic Mapping,"Context: Gamification is an emerging subject that has been applied in different areas, bringing contributions to different types of activities. Objective: This paper aims to characterize how gamification has been adopted in non-educational contexts of software engineering (SE) activities. Method: We performed a Systematic Mapping of the literature obtained from relevant databases of the area. The searches retrieved 2640 studies (published up to January 2020), of which 548 were duplicates, 82 were selected after applying the inclusion and exclusion criteria, and 21 were included via the backward snowballing technique, thus reaching a total of 103 studies to be analyzed. Results: Gamification provided benefits to activities like requirements specification, development, testing, project management, and support process. There is evidence of gamified support to some CMMI 2.0 Practice Areas. The most commonly used gamification elements are points and leaderboards. The main benefit achieved is the increased engagement and motivation to perform tasks. Conclusion: The number of publications and new research initiatives have increased over the years and, from the original authors’ reports, many positive results were achieved in SE activities. Despite this, gamification can still be explored for many SE tasks; for the addressed ones, empirical evidence is very limited.","Gamification, Software Engineering, Systematic Literature Mapping"
Software Engineering,Accessibility and Software Engineering Processes: A Systematic Literature Review,"Guidelines, techniques, and methods have been presented in the literature in recent years to contribute to the development of accessible software and to promote digital inclusion. Considering that software product quality depends on the quality of the development process, researchers have investigated how to include accessibility during the software development process in order to obtain accessible software. Two Systematic Literature Reviews (SLR) have been conducted in the past to identify such research initiatives. This paper presents a new SLR, considering the period from 2011 to 2019. The review of 94 primary studies showed the distribution of publications on different phases of the software life cycle, mainly the design and testing phases. The study also identified, for the first time, papers about accessibility and software process establishment. This result reinforces that, in fact, accessibility is not characterized as a property of the final software only. Instead, it evolves over the software life cycle. Besides, this study aims to provide designers and developers with an updated view of methods, tools, and other assets that contribute to process enrichment, valuing accessibility, as well as shows the gaps and challenges which deserve to be investigated.",AccessibilitySoftware Engineering Systematic Literature Review Design for disabilities Methods for accessibility
Software Engineering,Quality Assessment in Systematic Literature Reviews: A Software Engineering Perspective,"Context: Quality Assessment (QA) of reviewed literature is paramount to a Systematic Literature Review (SLR) as the quality of conclusions completely depends on the quality of selected literature. A number of researchers in Software Engineering (SE) have developed a variety of QA instruments and also reported their challenges. We previously conducted a tertiary study on SLRs with QA from 2004 to 2013, and reported the findings in 2015.  Objective: With the widespread use of SLRs in SE and the increasing adoption of QA in these SLRs in recent years, it is necessary to empirically investigate whether the previous conclusions are still valid and whether there are new insights to the subject in question using a larger and a more up-to-date SLR set. More importantly, we aim to depict a clear picture of QA used in SLRs in SE by aggregating and distilling good practices, including the commonly used QA instruments as well as the major roles and aspects of QA in research.  Method: An extended tertiary study was conducted with the newly collected SLRs from 2014 to 2018 and the original SLRs from 2004 to 2013 to systematically review the QA used by SLRs in SE during the 15-year period from 2004 to 2018. In addition, this extended study also compared and contrasted the findings of the previous study conducted in 2015.  Results: A total of 241 SLRs between 2004 and 2018 were included, from which we identified a number of QA instruments. These instruments are generally designed to focus on the rationality of study design, the rigor of study execution and analysis, and the credibility and contribution of study findings and conclusions, with the emphasis largely placed on its rigor. The quality data is mainly used for literature selection or as evidence to support conclusions.  Conclusions: QA has received much attention in SE in more recent years and the improvement is evident since the last study in 2015. New findings show that the aims are more concise, the instruments are more diverse and rigorous, and the criteria are more thoughtful.",Quality assessment Systematic (literature) review Tertiary study Empirical software engineering Evidence-based software engineering
Software Engineering,The Four Pillars of Research Software Engineering,"Building software that can support the huge growth in data and computation required by modern research needs individuals with increasingly specialist skill sets that take time to develop and maintain. The Research Software Engineering movement, which started in the UK and has been built up over recent years, aims to recognise and support these individuals. Why does research software matter to professional software development practitioners outside the research community? Research software can have great impact on the wider world and recent progress means the area can now be considered as a more realistic option for a professional software development career. In this article we present a structure, along with supporting evidence of real-world activities, that defines four elements that we believe are key to providing comprehensive and sustainable support for Research Software Engi- neering. We also highlight ways that the wider developer community can learn from, and engage with, these activities.",software engineering data computation develop
Software Engineering,Authorship Attribution of Source Code: A Language-Agnostic Approach and Applicability in Software Engineering,"Authorship attribution (i.e., determining who is the author of a piece of source code) is an established research topic. State-of-theart results for the authorship attribution problem look promising for the software engineering field, where they could be applied to detect plagiarized code and prevent legal issues. With this article, we first introduce a new language-agnostic approach to authorship attribution of source code. Then, we discuss limitations of existing synthetic datasets for authorship attribution, and propose a data collection approach that delivers datasets that better reflect aspects important for potential practical use in software engineering. Finally, we demonstrate that high accuracy of authorship attribution models on existing datasets drastically drops when they are evaluated on more realistic data. We outline next steps for the design and evaluation of authorship attribution models that could bring the research efforts closer to practical use for software engineering.","Copyrights, Machine learning, Methods of data collection, Software process, Software maintenance, Security"
Software Engineering,The realist approach for evaluation of computational intelligence in software engineering,Secured software development must employ a security mindset across software engineering practices. Software security must be considered during the requirements phase so that it is included throughout the development phase. Do the requirements gathering team get the proper input from the technical team? This paper unearths some of the data sources buried within software development phases and describes the potential approaches to understand them. Concepts such as machine learning and deep learning are explored to understand the data sources and explore how these learnings can be provided to the requirements gathering team. This knowledge system will help bring objectivity in the conversations between the requirements gathering team and the customer’s business team. A literature review is also done to secure requirements management and identify the possible gaps in providing future research direction to enhance our understanding. Feature engineering in the landscape of software development is explored to understand the data sources. Experts ofer their insight on the root cause of the lack of security focus in requirements gathering practices. The core theme is statistical modeling of all the software artifacts that hold information related to the software development life cycle. Strengthening of some traditional methods like threat modeling is also a key area explored. Subjectivity involved in these approaches can be made more objective.,Software engineering · Data science · Computational intelligence · Software requirements management · Threat modeling
Software Engineering,A Procedure and Guidelines for Analyzing Groups of Software Engineering Replications,"Researchers from different groups and institutions are collaborating on building groups of experiments by means of replication (i.e., conducting groups of replications). Disparate aggregation techniques are being applied to analyze groups of replications. The application of unsuitable techniques to aggregate replication results may undermine the potential of groups of replications to provide in-depth insights from experiment results. Objectives: Provide an analysis procedure with a set of embedded guidelines to aggregate software engineering (SE) replication results. Method: We compare the characteristics of groups of replications for SE and other mature experimental disciplines such as medicine and pharmacology. In view of their differences, the limitations with regard to the joint data analysis of groups of SE replications and the guidelines provided in mature experimental disciplines to analyze groups of replications, we build an analysis procedure with a set of embedded guidelines specifically tailored to the analysis of groups of SE replications. We apply the proposed analysis procedure to a representative group of SE replications to illustrate its use. Results: All the information contained within the raw data should be leveraged during the aggregation of replication results. The analysis procedure that we propose encourages the use of stratified individual participant data and aggregated data in tandem to analyze groups of SE replications. Conclusion: The aggregation techniques used to analyze groups of replications should be justified in research articles. This will increase the reliability and transparency of joint results. The proposed guidelines should ease this endeavor.","Replication, Statistical Analysis, Aggregated Data, Individual Participant Data, Narrative Synthesis."
Software Engineering,ndustry-Academia Research Collaboration in Software Engineering: The Certus Model,"Context: Research collaborations between software engineering industry and academia can provide significant benefits to both sides, including improved in- novation capacity for industry, and real-world environment for motivating and validating research ideas. However, building scalable and effective research col- laborations in software engineering is known to be challenging. While such challenges can be varied and many, in this paper we focus on the challenges of achieving participative knowledge creation supported by active dialog between industry and academia and continuous commitment to joint problem solving. Objective: This paper aims to understand what are the elements of a suc- cessful industry-academia collaboration that enable the culture of participative knowledge creation. Method: We conducted participant observation collecting qualitative data spanning 8 years of collaborative research between a software engineering research group on software V&V and the Norwegian IT sector. The collected data was analyzed and synthesized into a practical collaboration model, named the Certus Model. Results: The model is structured in seven phases, describing activities from setting up research projects to the exploitation of re- search results. As such, the Certus model advances other collaborations models from literature by delineating different phases covering the complete life cycle of participative research knowledge creation. Conclusion: The Certus model de- scribes the elements of a research collaboration process between researchers and practitioners in software engineering, grounded on the principles of research knowledge co-creation and continuous commitment to joint problem solving. The model can be applied and tested in other contexts where it may be adapted to the local context through experimentation.","Software engineering, Industry-academia collaboration, Research collaboration, Research knowledge co-creation, Collaboration model"
Software Engineering,PLS-SEM for Software Engineering Research: An Introduction and Survey,"Software Engineering (SE) researchers are increasingly paying attention to organizational and human factors. Rather than focusing only on variables that can be directly measured, such as lines of code, SE research studies now also consider unobservable variables, such as organizational culture and trust. To measure such latent variables, SE scholars have adopted Partial Least Squares Structural Equation Modeling (PLS-SEM), which is one member of the larger SEM family of statistical analysis techniques. As the SE field is facing the introduction of new methods such as PLS-SEM, a key issue is that not much is known about how to evaluate such studies. To help SE researchers learn about PLS-SEM, we draw on the latest methodological literature on PLS-SEM to synthesize an introduction. Further, we conducted a survey of PLS-SEM studies in the SE literature and evaluated those based on recommended guidelines.","Partial least squares, structural equation modeling, research methodology, critical review , software engineering "
Software Engineering,Explainable AI for Software Engineering,"The success of software engineering projects largely depends on complex decision-making. For example, which tasks should a developer do first, who should perform this task, is the software of high quality, is a software system reliable and resilient enough to deploy, etc. However, erroneous decisionmaking for these complex questions is costly in terms of money and reputation. Thus, Artificial Intelligence/Machine Learning (AI/ML) techniques have been widely used in software engineering for developing software analytics tools and techniques to improve decision-making, developer productivity, and software quality. However, the predictions of such AI/ML models for software engineering are still not practical (i.e., coarse-grained), not explainable, and not actionable. These concerns often hinder the adoption of AI/ML models in software engineering practices. In addition, many recent studies still focus on improving the accuracy, while a few of them focus on improving explainability. Are we moving in the right direction? How can we better improve the SE community (both research and education)? In this tutorial, we first provide a concise yet essential introduction to the most important aspects of Explainable AI and a hands-on tutorial of Explainable AI tools and techniques. Then, we introduce the fundamental knowledge of defect prediction (an example application of AI for Software Engineering). Finally, we demonstrate three successful case studies on how Explainable AI techniques can be used to address the aforementioned challenges by making the predictions of software defect prediction models more practical, explainable, and actionable. The materials are available at https://xai4se.github.io","Explainable AI, Software Engineering"
Software Engineering,Novel Triplex Procedure for Ranking the Ability of Software Engineering Students Based on Two levels of AHP and Group TOPSIS Techniques,"Ranking the strengths and weaknesses of software engineering students in software development life cycle (SDLC) process level is a challenging task owing to (1) data variation, (2) multievaluation criteria, (3) criterion importance and (4) alternative member importance. According to the existing literature, no specified procedure can rank the ability of software engineering students based on SDLC process levels to figure out the strengths and weaknesses of each student. This study aims to present a novel triplex procedure for ranking the ability of software engineering students to address the literature gap. The methodology of the proposed work is presented on the basis of three phases. In the identification phase, four steps are implemented, namely, processing dataset, identifying the criteria, distributing the courses to the software engineering body of knowledge and proposing the pre-decision matrix (DM). The data comprise the GPA and soft skills from 60 software engineering students who graduated from Universiti Pendidikan Sultan Idris in 2016. In the pre-processing phase, three steps are involved as follows. Analytic hierarchy process (AHP) is first used to assign weights to the courses and then multiply the assigned weight by courses, which is the first procedure in the proposed work. In this phase, the construction of DM is presented based on multimeasurement criteria (GPA and soft skills), with SDLC process levels as alternatives. In the development phase, AHP is used again to weight the multimeasurement criteria, and this is the second procedure. In such case, the coordinator and head of the software engineering department are consulted to obtain subjective judgments for each criterion. Technique for order performance by similarity to ideal solution (TOPSIS) is then used to rank the students, which is the third procedure. In the validation, statistical analysis is performed to validate the results by checking the accuracy of the systematic ranking. Results show that (1) integrating AHP and group TOPSIS is suitable for ranking the ability of students. (2) The 60 students are categorized into five ranking groups based on their strength level: 14 collector requirements, 13 designers, 5 programmers, 13 testers and 15 maintenances. (3) Significant differences are observed between the groups’ scores for each level of SDLC, indicating that the ranking results are identical for all levels.",Multi criteria decision-making techniques measurement criteria AHP TOPSIS software engineering students
Software Engineering,Mobile App Privacy in Software Engineering Research: A Systematic Mapping Study,"Mobile applications (apps) have become deeply personal, constantly demanding access to privacy-sensitive information in exchange for more personalized user experiences. Such privacy-invading practices have generated major multidimensional and unconventional privacy concerns among app users. To address these concerns, the research on mobile app privacy has experienced rapid growth over the past decade. In general, this line of research is aimed at systematically exposing the privacy practices of apps and proposing solutions to protect the privacy of mobile app users. In this survey paper, we conduct a systematic mapping study of 54 Software Engineering (SE) primary studies on mobile app privacy. Our objectives are to a) explore trends in SE app privacy research, b) categorize existing evidence, and c) identify potential directions for future research. Our results show that existing literature can be divided into four main categories: privacy policy, requirements, user perspective, and leak detection. Furthermore, our survey reveals an imbalance between these categories— majority of existing research focuses on proposing tools for detecting privacy leaks, with less studies targeting privacy requirements and policy and even less on user perspective. Finally, our survey exposes several gaps in existing research and suggests areas for improvement","Privacy, mobile application, systematic mapping study"
Software Engineering,BERT-Based Sentiment Analysis: A Software Engineering Perspective,"Sentiment analysis can provide a suitable lead for the tools used in software engineering along with the API recommendation sys- tems and relevant libraries to be used. In this context, the existing tools like SentiCR, SentiStrength-SE, etc. exhibited low f1-scores that com- pletely defeats the purpose of deployment of such strategies, thereby there is enough scope for performance improvement. Recent advance- ments show that transformer based pre-trained models (e.g., BERT, RoBERTa, ALBERT, etc.) have displayed better results in the text classi- fication task. Following this context, the present research explores differ- ent BERT-based models to analyze the sentences in GitHub comments, Jira comments, and Stack Overflow posts. The paper presents three dif- ferent strategies to analyse BERT based model for sentiment analysis, where in the first strategy the BERT based pre-trained models are fine- tuned; in the second strategy an ensemble model is developed from BERT variants, and in the third strategy a compressed model (Distil BERT) is used. The experimental results show that the BERT based ensemble ap- proach and the compressed BERT model attain improvements by 6-12% over prevailing tools for the F1 measure on all three datasets.",Sentiment analysis · Transformer · Deep learning · Software engineering · BERT
Software Engineering,Understanding and Improving Artifact Sharing in Software Engineering Research,"In recent years, many software engineering researchers have begun to include artifacts alongside their research papers. Ideally, artifacts, including tools, benchmarks, and data, support the dissemination of ideas, provide evidence for research claims, and serve as a starting point for future research. However, in practice, artifacts suffer from a variety of issues that prevent the realization of their full potential. To help the software engineering community realize the full potential of ar- tifacts, we seek to understand the challenges involved in the creation, sharing, and use of artifacts. To that end, we perform a mixed-methods study including a survey of artifacts in software engineering publications, and an online survey of 153 software engineering researchers. By analyzing the perspectives of artifact creators, users, and reviewers, we identify several high-level challenges that affect the quality of artifacts including mismatched expectations between these groups, and a lack of sufficient reward for both creators and reviewers. Using Diffusion of Innovations (DoI) as an analytical framework, we examine how these challenges relate to one another, and build an understanding of the factors that affect the sharing and success of artifacts. Finally, we make recommendations to improve the quality of artifacts based on our results and existing best practices",replication · artifacts · reproducibility · implementation science · replicability · diffusion
